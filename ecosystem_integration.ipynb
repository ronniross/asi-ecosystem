{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ASI Ecosystem Integration - Google Colab Notebook"
      ],
      "metadata": {
        "id": "Y3ihMtufbl2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ecosystem Cloning - Part I**"
      ],
      "metadata": {
        "id": "q4NHcKzIJOLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Setup and Prerequisites\n",
        "print(\"Setting up ASI Ecosystem Integration...\")\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Change to the content directory in Colab\n",
        "os.chdir('/content')\n",
        "print(f\"Current working directory: {os.getcwd()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E37P48_Jbn7K",
        "outputId": "a9766aea-46ac-4ca9-b4ac-7859c3015f39"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up ASI Ecosystem Integration...\n",
            "Current working directory: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Clone the Main ASI Ecosystem Repository\n",
        "print(\"Step 1: Cloning the main asi-ecosystem repository...\")\n",
        "\n",
        "# Remove any existing asi-ecosystem directory\n",
        "if os.path.exists('asi-ecosystem'):\n",
        "    print(\"Removing existing asi-ecosystem directory...\")\n",
        "    subprocess.run(['rm', '-rf', 'asi-ecosystem'], check=True)\n",
        "\n",
        "# Clone the main repository\n",
        "result = subprocess.run([\n",
        "    'git', 'clone',\n",
        "    'https://github.com/ronniross/asi-ecosystem.git'\n",
        "], capture_output=True, text=True)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"Successfully cloned asi-ecosystem repository\")\n",
        "else:\n",
        "    print(\"Error cloning repository:\")\n",
        "    print(result.stderr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28AgmXnCbtGG",
        "outputId": "35b9e397-1c2c-4521-827b-b20e43a6ab5c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Cloning the main asi-ecosystem repository...\n",
            "Successfully cloned asi-ecosystem repository\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Navigate to the Directory and Check Contents\n",
        "print(\"\\nStep 2: Navigating into the directory...\")\n",
        "os.chdir('/content/asi-ecosystem')\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "\n",
        "print(\"\\nRepository contents:\")\n",
        "for item in os.listdir('.'):\n",
        "    print(f\"  {item}\" if os.path.isdir(item) else f\"  {item}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i7sxWJ3b0uC",
        "outputId": "66e4f839-1de0-4346-cab7-045f0337d36a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 2: Navigating into the directory...\n",
            "Current working directory: /content/asi-ecosystem\n",
            "\n",
            "Repository contents:\n",
            "  scripts\n",
            "  requirements.txt\n",
            "  ecosystem_integration.ipynb\n",
            "  ecosystem_integration.md\n",
            "  README.md\n",
            "  .git\n",
            "  LICENSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Check if the Script Exists and Make it Executable\n",
        "script_path = './scripts/clone_ecosystem.sh'\n",
        "print(f\"\\nChecking for script at: {script_path}\")\n",
        "\n",
        "if os.path.exists(script_path):\n",
        "    print(\"Script found!\")\n",
        "    # Make the script executable\n",
        "    subprocess.run(['chmod', '+x', script_path], check=True)\n",
        "    print(\"Made script executable\")\n",
        "else:\n",
        "    print(\"Script not found. Listing scripts directory:\")\n",
        "    if os.path.exists('scripts'):\n",
        "        for item in os.listdir('scripts'):\n",
        "            print(f\"  scripts/{item}\")\n",
        "    else:\n",
        "        print(\"  scripts directory does not exist\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePhjo7vwcWUM",
        "outputId": "f6f3ba72-c43c-4bbc-de9b-b7a661d7e585"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checking for script at: ./scripts/clone_ecosystem.sh\n",
            "Script found!\n",
            "Made script executable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Execute the Integration Script\n",
        "print(\"\\nStep 3: Running the ecosystem integration script...\")\n",
        "\n",
        "if os.path.exists(script_path):\n",
        "    try:\n",
        "        # Run the script and capture output\n",
        "        result = subprocess.run([script_path],\n",
        "                              capture_output=True,\n",
        "                              text=True,\n",
        "                              cwd='/content/asi-ecosystem')\n",
        "\n",
        "        print(\"Script output:\")\n",
        "        print(result.stdout)\n",
        "\n",
        "        if result.stderr:\n",
        "            print(\"Script errors/warnings:\")\n",
        "            print(result.stderr)\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(\"Script executed successfully!\")\n",
        "        else:\n",
        "            print(f\"Script failed with return code: {result.returncode}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error executing script: {e}\")\n",
        "else:\n",
        "    print(\"Cannot execute script - file not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJchn-n5ccmK",
        "outputId": "f5e92e14-416f-4897-a063-9b24d263b5d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 3: Running the ecosystem integration script...\n",
            "Script output:\n",
            "Starting the ASI Ecosystem cloning process...\n",
            " Creating directory: 'repositories'...\n",
            "ðŸ”Ž Finding repositories in README.md...\n",
            " Cloning https://github.com/ronniross/asi-active-learning-dataset...\n",
            " Cloning https://github.com/ronniross/asi-algorithm-dataset...\n",
            " Cloning https://github.com/ronniross/asi-backups...\n",
            " Cloning https://github.com/ronniross/asi-core-protocol...\n",
            " Cloning https://github.com/ronniross/asi-dynamic-core...\n",
            " Cloning https://github.com/ronniross/asi-ecosystem...\n",
            " Cloning https://github.com/ronniross/asi-inference-protocol...\n",
            " Cloning https://github.com/ronniross/asi-protosymbiotic-signal...\n",
            " Cloning https://github.com/ronniross/asi-safeguards...\n",
            " Cloning https://github.com/ronniross/asi-symbiotic-signal...\n",
            " Cloning https://github.com/ronniross/bias-reflector...\n",
            " Cloning https://github.com/ronniross/cognitive-engine...\n",
            " Cloning https://github.com/ronniross/eco-benchmark...\n",
            " Cloning https://github.com/ronniross/eco-datacenter...\n",
            " Cloning https://github.com/ronniross/emergence-engine...\n",
            " Cloning https://github.com/ronniross/healing-engine...\n",
            " Cloning https://github.com/ronniross/latent-memory...\n",
            " Cloning https://github.com/ronniross/llm-confidence-scorer...\n",
            " Cloning https://github.com/ronniross/llm-heatmap-visualizer...\n",
            " Cloning https://github.com/ronniross/saliency-heatmap-visualizer...\n",
            " Cloning https://github.com/ronniross/symbiotic-core-library...\n",
            "All repositories have been cloned into the 'repositories' directory.\n",
            "ASI Ecosystem clone setup complete!\n",
            "\n",
            "Script errors/warnings:\n",
            "Cloning into 'asi-active-learning-dataset'...\n",
            "Cloning into 'asi-algorithm-dataset'...\n",
            "Cloning into 'asi-backups'...\n",
            "Cloning into 'asi-core-protocol'...\n",
            "Cloning into 'asi-dynamic-core'...\n",
            "Cloning into 'asi-ecosystem'...\n",
            "Cloning into 'asi-inference-protocol'...\n",
            "Cloning into 'asi-protosymbiotic-signal'...\n",
            "Cloning into 'asi-safeguards'...\n",
            "Cloning into 'asi-symbiotic-signal'...\n",
            "Cloning into 'bias-reflector'...\n",
            "Cloning into 'cognitive-engine'...\n",
            "Cloning into 'eco-benchmark'...\n",
            "Cloning into 'eco-datacenter'...\n",
            "Cloning into 'emergence-engine'...\n",
            "Cloning into 'healing-engine'...\n",
            "Cloning into 'latent-memory'...\n",
            "Cloning into 'llm-confidence-scorer'...\n",
            "Cloning into 'llm-heatmap-visualizer'...\n",
            "Cloning into 'saliency-heatmap-visualizer'...\n",
            "Cloning into 'symbiotic-core-library'...\n",
            "\n",
            "Script executed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Verify the Final Result\n",
        "print(\"\\nStep 4: Verifying the final result...\")\n",
        "\n",
        "print(f\"Contents of {os.getcwd()}:\")\n",
        "for item in sorted(os.listdir('.')):\n",
        "    if os.path.isdir(item):\n",
        "        print(f\"{item}/\")\n",
        "        # If it's the repositories folder, show its contents\n",
        "        if item == 'repositories':\n",
        "            repo_path = os.path.join('.', item)\n",
        "            if os.path.exists(repo_path):\n",
        "                print(f\"  Contents of {item}:\")\n",
        "                for repo in sorted(os.listdir(repo_path)):\n",
        "                    print(f\"    {repo}/\")\n",
        "    else:\n",
        "        print(f\" {item}\")\n",
        "\n",
        "print(\"\\n ASI Ecosystem Integration Complete!\")\n",
        "print(\"All component repositories should now be organized in the 'repositories' folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA7cBUqmchIt",
        "outputId": "d629a080-6f36-423d-af22-a304752fbdeb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 4: Verifying the final result...\n",
            "Contents of /content/asi-ecosystem:\n",
            ".git/\n",
            " LICENSE\n",
            " README.md\n",
            " ecosystem_integration.ipynb\n",
            " ecosystem_integration.md\n",
            "repositories/\n",
            "  Contents of repositories:\n",
            "    asi-active-learning-dataset/\n",
            "    asi-algorithm-dataset/\n",
            "    asi-backups/\n",
            "    asi-core-protocol/\n",
            "    asi-dynamic-core/\n",
            "    asi-ecosystem/\n",
            "    asi-inference-protocol/\n",
            "    asi-protosymbiotic-signal/\n",
            "    asi-safeguards/\n",
            "    asi-symbiotic-signal/\n",
            "    bias-reflector/\n",
            "    cognitive-engine/\n",
            "    eco-benchmark/\n",
            "    eco-datacenter/\n",
            "    emergence-engine/\n",
            "    healing-engine/\n",
            "    latent-memory/\n",
            "    llm-confidence-scorer/\n",
            "    llm-heatmap-visualizer/\n",
            "    saliency-heatmap-visualizer/\n",
            "    symbiotic-core-library/\n",
            " requirements.txt\n",
            "scripts/\n",
            "\n",
            " ASI Ecosystem Integration Complete!\n",
            "All component repositories should now be organized in the 'repositories' folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Optional - List All Cloned Repositories with Details\n",
        "print(\"\\n Summary of cloned repositories:\")\n",
        "repositories_path = './repositories'\n",
        "\n",
        "if os.path.exists(repositories_path):\n",
        "    repos = [d for d in os.listdir(repositories_path)\n",
        "             if os.path.isdir(os.path.join(repositories_path, d))]\n",
        "\n",
        "    print(f\"Total repositories cloned: {len(repos)}\")\n",
        "    for i, repo in enumerate(sorted(repos), 1):\n",
        "        repo_path = os.path.join(repositories_path, repo)\n",
        "        # Check if it's a git repository\n",
        "        git_path = os.path.join(repo_path, '.git')\n",
        "        status = \"Git repo\" if os.path.exists(git_path) else \"Not a git repo\"\n",
        "        print(f\"{i:2d}. {repo:<30} {status}\")\n",
        "else:\n",
        "    print(\"No repositories folder found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsrieFWUcmVa",
        "outputId": "f7cf79c1-d915-48c8-cfbe-eaed363cc4f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Summary of cloned repositories:\n",
            "Total repositories cloned: 21\n",
            " 1. asi-active-learning-dataset    Git repo\n",
            " 2. asi-algorithm-dataset          Git repo\n",
            " 3. asi-backups                    Git repo\n",
            " 4. asi-core-protocol              Git repo\n",
            " 5. asi-dynamic-core               Git repo\n",
            " 6. asi-ecosystem                  Git repo\n",
            " 7. asi-inference-protocol         Git repo\n",
            " 8. asi-protosymbiotic-signal      Git repo\n",
            " 9. asi-safeguards                 Git repo\n",
            "10. asi-symbiotic-signal           Git repo\n",
            "11. bias-reflector                 Git repo\n",
            "12. cognitive-engine               Git repo\n",
            "13. eco-benchmark                  Git repo\n",
            "14. eco-datacenter                 Git repo\n",
            "15. emergence-engine               Git repo\n",
            "16. healing-engine                 Git repo\n",
            "17. latent-memory                  Git repo\n",
            "18. llm-confidence-scorer          Git repo\n",
            "19. llm-heatmap-visualizer         Git repo\n",
            "20. saliency-heatmap-visualizer    Git repo\n",
            "21. symbiotic-core-library         Git repo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Integrity Audit - Part II**"
      ],
      "metadata": {
        "id": "aydWI04IGlVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 8: Import Required Libraries for Integrity Verification\n",
        "print(\"Importing libraries for integrity verification...\")\n",
        "import hashlib\n",
        "import json\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Libraries imported successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao3AZ1muGjWB",
        "outputId": "322c53e1-3ee7-4884-aef1-f90a30bb2c19"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing libraries for integrity verification...\n",
            "Libraries imported successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Define Integrity Verification Functions\n",
        "print(\"Setting up integrity verification functions...\\n\")\n",
        "\n",
        "class IntegrityVerifier:\n",
        "    def __init__(self, repo_path):\n",
        "        self.repo_path = Path(repo_path)\n",
        "        self.repo_name = self.repo_path.name\n",
        "        self.results = {\n",
        "            'repo': self.repo_name,\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'levels': {}\n",
        "        }\n",
        "\n",
        "    def run_git_command(self, cmd):\n",
        "        \"\"\"Execute git command and return output\"\"\"\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            cwd=self.repo_path,\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            shell=False\n",
        "        )\n",
        "        return result.stdout.strip(), result.stderr.strip(), result.returncode\n",
        "\n",
        "    def level_1_commit_and_tree_hash(self):\n",
        "        \"\"\"Level 1: Compare local vs remote commit and tree hashes\"\"\"\n",
        "        print(f\"  [Level 1] Commit & Tree Hash Comparison\")\n",
        "\n",
        "        # Get local commit hash\n",
        "        local_commit, _, ret1 = self.run_git_command(['git', 'rev-parse', 'HEAD'])\n",
        "\n",
        "        # Get local tree hash\n",
        "        local_tree, _, ret2 = self.run_git_command(['git', 'rev-parse', 'HEAD^{tree}'])\n",
        "\n",
        "        # Get remote commit hash\n",
        "        remote_info, _, ret3 = self.run_git_command(['git', 'ls-remote', 'origin', 'HEAD'])\n",
        "        remote_commit = remote_info.split()[0] if remote_info else None\n",
        "\n",
        "        if ret1 != 0 or ret2 != 0 or ret3 != 0:\n",
        "            self.results['levels']['level_1'] = {\n",
        "                'status': 'ERROR',\n",
        "                'message': 'Failed to retrieve git hashes'\n",
        "            }\n",
        "            print(f\"    [x] ERROR: Failed to retrieve git information\")\n",
        "            return False\n",
        "\n",
        "        commit_match = local_commit == remote_commit\n",
        "\n",
        "        self.results['levels']['level_1'] = {\n",
        "            'status': 'PASS' if commit_match else 'FAIL',\n",
        "            'local_commit': local_commit,\n",
        "            'remote_commit': remote_commit,\n",
        "            'local_tree': local_tree,\n",
        "            'commit_match': commit_match\n",
        "        }\n",
        "\n",
        "        if commit_match:\n",
        "            print(f\"    [âœ“] PASS - Commits match\")\n",
        "            print(f\"       Commit: {local_commit[:12]}...\")\n",
        "            print(f\"       Tree:   {local_tree[:12]}...\")\n",
        "        else:\n",
        "            print(f\"    [x] FAIL - Commit mismatch\")\n",
        "            print(f\"       Local:  {local_commit[:12]}...\")\n",
        "            print(f\"       Remote: {remote_commit[:12]}...\")\n",
        "\n",
        "        return commit_match\n",
        "\n",
        "    def level_2_git_fsck(self):\n",
        "        \"\"\"Level 2: Deep git repository integrity check\"\"\"\n",
        "        print(f\"  [Level 2] Git Repository Integrity (fsck)\")\n",
        "\n",
        "        output, stderr, returncode = self.run_git_command(['git', 'fsck', '--full'])\n",
        "\n",
        "        # git fsck returns 0 if no issues\n",
        "        passed = returncode == 0 and not any(word in output.lower() for word in ['error', 'missing', 'corrupt'])\n",
        "\n",
        "        self.results['levels']['level_2'] = {\n",
        "            'status': 'PASS' if passed else 'FAIL',\n",
        "            'returncode': returncode,\n",
        "            'issues_found': [] if passed else output.split('\\n')[:5]  # First 5 issues\n",
        "        }\n",
        "\n",
        "        if passed:\n",
        "            print(f\"    [âœ“] PASS - Repository integrity verified\")\n",
        "        else:\n",
        "            print(f\"    [x] FAIL - Repository integrity issues detected\")\n",
        "            if output:\n",
        "                print(f\"       Issues: {output[:100]}...\")\n",
        "\n",
        "        return passed\n",
        "\n",
        "    def level_3_file_hashing(self):\n",
        "        \"\"\"Level 3: File-by-file and folder structure verification\"\"\"\n",
        "        print(f\"  [Level 3] File-by-File Hash Verification\")\n",
        "\n",
        "        # Get list of all tracked files\n",
        "        files_output, _, ret = self.run_git_command(['git', 'ls-files'])\n",
        "\n",
        "        if ret != 0:\n",
        "            self.results['levels']['level_3'] = {\n",
        "                'status': 'ERROR',\n",
        "                'message': 'Failed to list git files'\n",
        "            }\n",
        "            print(f\"    [x] ERROR: Failed to list files\")\n",
        "            return False\n",
        "\n",
        "        files = files_output.split('\\n') if files_output else []\n",
        "\n",
        "        file_hashes = {}\n",
        "        corrupted_files = []\n",
        "        total_files = len(files)\n",
        "\n",
        "        # Calculate hash for each file\n",
        "        for file in files[:100]:  # Limit to first 100 files for performance\n",
        "            if not file:\n",
        "                continue\n",
        "            file_path = self.repo_path / file\n",
        "            if file_path.exists() and file_path.is_file():\n",
        "                try:\n",
        "                    with open(file_path, 'rb') as f:\n",
        "                        file_hash = hashlib.sha256(f.read()).hexdigest()\n",
        "                        file_hashes[file] = file_hash\n",
        "\n",
        "                        # Verify against git's hash\n",
        "                        git_hash, _, ret = self.run_git_command(['git', 'hash-object', file])\n",
        "                        if ret != 0 or not git_hash:\n",
        "                            corrupted_files.append(file)\n",
        "                except Exception as e:\n",
        "                    corrupted_files.append(file)\n",
        "\n",
        "        passed = len(corrupted_files) == 0\n",
        "\n",
        "        self.results['levels']['level_3'] = {\n",
        "            'status': 'PASS' if passed else 'FAIL',\n",
        "            'total_files_checked': len(file_hashes),\n",
        "            'total_files_in_repo': total_files,\n",
        "            'corrupted_files': corrupted_files,\n",
        "            'sample_hashes': dict(list(file_hashes.items())[:3])  # First 3 as sample\n",
        "        }\n",
        "\n",
        "        if passed:\n",
        "            print(f\"    [âœ“] PASS - All files verified ({len(file_hashes)} checked)\")\n",
        "            if file_hashes:\n",
        "                sample_file = list(file_hashes.keys())[0]\n",
        "                print(f\"       Sample: {sample_file[:40]}... -> {file_hashes[sample_file][:12]}...\")\n",
        "        else:\n",
        "            print(f\"    [x] FAIL - {len(corrupted_files)} corrupted files detected\")\n",
        "            for cf in corrupted_files[:3]:\n",
        "                print(f\"       - {cf}\")\n",
        "\n",
        "        return passed\n",
        "\n",
        "    def level_4_tree_comparison(self):\n",
        "        \"\"\"Level 4: Complete tree hash comparison\"\"\"\n",
        "        print(f\"  [Level 4] Complete Tree Hash Verification\")\n",
        "\n",
        "        # Get local tree\n",
        "        local_tree, _, ret1 = self.run_git_command(['git', 'rev-parse', 'HEAD^{tree}'])\n",
        "\n",
        "        # Fetch latest from remote\n",
        "        _, _, ret2 = self.run_git_command(['git', 'fetch', 'origin', '--quiet'])\n",
        "\n",
        "        # Get remote tree\n",
        "        remote_tree, _, ret3 = self.run_git_command(['git', 'rev-parse', 'origin/HEAD^{tree}'])\n",
        "\n",
        "        if ret1 != 0 or ret3 != 0:\n",
        "            self.results['levels']['level_4'] = {\n",
        "                'status': 'ERROR',\n",
        "                'message': 'Failed to retrieve tree hashes'\n",
        "            }\n",
        "            print(f\"    [x] ERROR: Failed to retrieve tree information\")\n",
        "            return False\n",
        "\n",
        "        tree_match = local_tree == remote_tree\n",
        "\n",
        "        self.results['levels']['level_4'] = {\n",
        "            'status': 'PASS' if tree_match else 'FAIL',\n",
        "            'local_tree': local_tree,\n",
        "            'remote_tree': remote_tree,\n",
        "            'tree_match': tree_match\n",
        "        }\n",
        "\n",
        "        if tree_match:\n",
        "            print(f\"    [âœ“] PASS - Tree hashes match\")\n",
        "            print(f\"       Tree: {local_tree[:12]}...\")\n",
        "        else:\n",
        "            print(f\"    [x] FAIL - Tree hash mismatch\")\n",
        "            print(f\"       Local:  {local_tree[:12]}...\")\n",
        "            print(f\"       Remote: {remote_tree[:12]}...\")\n",
        "\n",
        "        return tree_match\n",
        "\n",
        "    def verify(self, levels=[1, 2, 3, 4]):\n",
        "        \"\"\"Run verification for specified levels\"\"\"\n",
        "        print(f\"\\n[VERIFYING] {self.repo_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        level_functions = {\n",
        "            1: self.level_1_commit_and_tree_hash,\n",
        "            2: self.level_2_git_fsck,\n",
        "            3: self.level_3_file_hashing,\n",
        "            4: self.level_4_tree_comparison\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "        for level in sorted(levels):\n",
        "            if level in level_functions:\n",
        "                results[level] = level_functions[level]()\n",
        "            else:\n",
        "                print(f\"  [!] Warning: Level {level} not recognized\")\n",
        "\n",
        "        # Overall status\n",
        "        all_passed = all(results.values())\n",
        "        self.results['overall_status'] = 'PASS' if all_passed else 'FAIL'\n",
        "\n",
        "        status_symbol = \"[âœ“]\" if all_passed else \"[x]\"\n",
        "        print(f\"\\n  {status_symbol} Overall: {'PASS' if all_passed else 'FAIL'}\")\n",
        "\n",
        "        return self.results\n",
        "\n",
        "print(\"[âœ“] Integrity verification functions ready\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu4nJxM-H14H",
        "outputId": "898d9825-4718-432e-da5b-9d1a6b3250fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up integrity verification functions...\n",
            "\n",
            "[âœ“] Integrity verification functions ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Configure Integrity Verification Levels\n",
        "print(\"Integrity Verification Configuration\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nAvailable verification levels:\")\n",
        "print(\"  Level 1: Commit & Tree Hash Comparison (Fast)\")\n",
        "print(\"  Level 2: Git Repository Integrity Check (Medium)\")\n",
        "print(\"  Level 3: File-by-File Hash Verification (Slow)\")\n",
        "print(\"  Level 4: Complete Tree Hash Comparison (Fast)\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# USER CONFIGURATION: Choose which levels to run\n",
        "VERIFICATION_LEVELS = [1, 2, 3, 4]  # Modify this list to choose levels\n",
        "\n",
        "print(f\"\\n[âœ“] Running levels: {VERIFICATION_LEVELS}\")\n",
        "print(f\"[âœ“] This will verify all repositories in the 'repositories' folder\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QatMkQH4H5rR",
        "outputId": "346cc888-0be1-4be9-f3d3-e1bf9d1fbc9f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Integrity Verification Configuration\n",
            "============================================================\n",
            "\n",
            "Available verification levels:\n",
            "  Level 1: Commit & Tree Hash Comparison (Fast)\n",
            "  Level 2: Git Repository Integrity Check (Medium)\n",
            "  Level 3: File-by-File Hash Verification (Slow)\n",
            "  Level 4: Complete Tree Hash Comparison (Fast)\n",
            "\n",
            "============================================================\n",
            "\n",
            "[âœ“] Running levels: [1, 2, 3, 4]\n",
            "[âœ“] This will verify all repositories in the 'repositories' folder\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Run Integrity Verification on All Repositories\n",
        "print(\"Starting Integrity Verification Process\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "repositories_path = Path('/content/asi-ecosystem/repositories')\n",
        "\n",
        "if not repositories_path.exists():\n",
        "    print(\"[x] Error: repositories folder not found!\")\n",
        "else:\n",
        "    repos = [d for d in repositories_path.iterdir() if d.is_dir() and not d.name.startswith('.')]\n",
        "\n",
        "    print(f\"Found {len(repos)} repositories to verify\\n\")\n",
        "\n",
        "    all_results = []\n",
        "    verification_start = datetime.now()\n",
        "\n",
        "    for i, repo_path in enumerate(sorted(repos), 1):\n",
        "        print(f\"\\n[{i}/{len(repos)}]\")\n",
        "        verifier = IntegrityVerifier(repo_path)\n",
        "        result = verifier.verify(levels=VERIFICATION_LEVELS)\n",
        "        all_results.append(result)\n",
        "\n",
        "    verification_end = datetime.now()\n",
        "    duration = (verification_end - verification_start).total_seconds()\n",
        "\n",
        "    # Summary Statistics\n",
        "    print(\"\\n\\n\" + \"=\"*60)\n",
        "    print(\"VERIFICATION SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    passed = sum(1 for r in all_results if r['overall_status'] == 'PASS')\n",
        "    failed = len(all_results) - passed\n",
        "\n",
        "    print(f\"\\n[âœ“] Total Repositories: {len(all_results)}\")\n",
        "    print(f\"[âœ“] Passed: {passed}\")\n",
        "    print(f\"[âœ“] Failed: {failed}\")\n",
        "    print(f\"[âœ“] Duration: {duration:.2f} seconds\")\n",
        "\n",
        "    # Level-by-level summary\n",
        "    print(f\"\\nLevel-by-Level Results:\")\n",
        "    for level in VERIFICATION_LEVELS:\n",
        "        level_passed = sum(1 for r in all_results\n",
        "                          if f'level_{level}' in r['levels']\n",
        "                          and r['levels'][f'level_{level}']['status'] == 'PASS')\n",
        "        level_total = sum(1 for r in all_results if f'level_{level}' in r['levels'])\n",
        "        print(f\"   Level {level}: {level_passed}/{level_total} passed\")\n",
        "\n",
        "    # Failed repositories detail\n",
        "    if failed > 0:\n",
        "        print(f\"\\nFailed Repositories:\")\n",
        "        for result in all_results:\n",
        "            if result['overall_status'] == 'FAIL':\n",
        "                print(f\"\\n   [x] {result['repo']}\")\n",
        "                for level_key, level_data in result['levels'].items():\n",
        "                    if level_data['status'] != 'PASS':\n",
        "                        level_num = level_key.replace('level_', '')\n",
        "                        print(f\"      - Level {level_num}: {level_data['status']}\")\n",
        "                        if 'message' in level_data:\n",
        "                            print(f\"        {level_data['message']}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"[âœ“] Integrity verification complete!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Store results for optional export\n",
        "    integrity_results = {\n",
        "        'verification_date': verification_start.isoformat(),\n",
        "        'duration_seconds': duration,\n",
        "        'levels_checked': VERIFICATION_LEVELS,\n",
        "        'summary': {\n",
        "            'total': len(all_results),\n",
        "            'passed': passed,\n",
        "            'failed': failed\n",
        "        },\n",
        "        'repositories': all_results\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy5vjvLcIKWB",
        "outputId": "a404e6ce-a25f-4dcf-d175-83c9e61fe89d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Integrity Verification Process\n",
            "============================================================\n",
            "\n",
            "Found 21 repositories to verify\n",
            "\n",
            "\n",
            "[1/21]\n",
            "\n",
            "[VERIFYING] asi-active-learning-dataset\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 1b0d87e307a3...\n",
            "       Tree:   cb98f0bc19f8...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (100 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: cb98f0bc19f8...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[2/21]\n",
            "\n",
            "[VERIFYING] asi-algorithm-dataset\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 46cb5bf3f880...\n",
            "       Tree:   6eb101c2c4a2...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (2 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 6eb101c2c4a2...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[3/21]\n",
            "\n",
            "[VERIFYING] asi-backups\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 251299739195...\n",
            "       Tree:   b9df58a154dc...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (100 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: b9df58a154dc...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[4/21]\n",
            "\n",
            "[VERIFYING] asi-core-protocol\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: ae2a7c5e4eda...\n",
            "       Tree:   788372a9a101...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (8 checked)\n",
            "       Sample: ASI_Core_Protocol.json... -> 8836cafc1e79...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 788372a9a101...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[5/21]\n",
            "\n",
            "[VERIFYING] asi-dynamic-core\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: bb198611cffb...\n",
            "       Tree:   e4d2cbfc39c0...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (2 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: e4d2cbfc39c0...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[6/21]\n",
            "\n",
            "[VERIFYING] asi-ecosystem\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: f6fcb77655b7...\n",
            "       Tree:   8573288295c1...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (7 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 8573288295c1...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[7/21]\n",
            "\n",
            "[VERIFYING] asi-inference-protocol\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 653f9f234897...\n",
            "       Tree:   0a0342f79124...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (2 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 0a0342f79124...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[8/21]\n",
            "\n",
            "[VERIFYING] asi-protosymbiotic-signal\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 188608d11a24...\n",
            "       Tree:   e6ca33cadeee...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (15 checked)\n",
            "       Sample: Cargo.toml... -> d9ad5837a11f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: e6ca33cadeee...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[9/21]\n",
            "\n",
            "[VERIFYING] asi-safeguards\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: d413c6cb749d...\n",
            "       Tree:   394d35765ed8...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (4 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 394d35765ed8...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[10/21]\n",
            "\n",
            "[VERIFYING] asi-symbiotic-signal\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: dd5cbf0123b1...\n",
            "       Tree:   8716af53abbc...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (2 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 8716af53abbc...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[11/21]\n",
            "\n",
            "[VERIFYING] bias-reflector\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: d177bca8c6d8...\n",
            "       Tree:   739ae837469a...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (3 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 739ae837469a...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[12/21]\n",
            "\n",
            "[VERIFYING] cognitive-engine\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: cf520d034dc8...\n",
            "       Tree:   0ccd21a12d2d...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (2 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 0ccd21a12d2d...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[13/21]\n",
            "\n",
            "[VERIFYING] eco-benchmark\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 79e8fa1061ed...\n",
            "       Tree:   210649f2650d...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (4 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 210649f2650d...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[14/21]\n",
            "\n",
            "[VERIFYING] eco-datacenter\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: b87fd7d9aee3...\n",
            "       Tree:   aee35b2ea9cc...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (2 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: aee35b2ea9cc...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[15/21]\n",
            "\n",
            "[VERIFYING] emergence-engine\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: f11153ddbaf3...\n",
            "       Tree:   b7277d5b8b97...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (10 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: b7277d5b8b97...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[16/21]\n",
            "\n",
            "[VERIFYING] healing-engine\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 22e16263e4a0...\n",
            "       Tree:   b79c91bbd49a...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (4 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: b79c91bbd49a...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[17/21]\n",
            "\n",
            "[VERIFYING] latent-memory\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 510aff82670a...\n",
            "       Tree:   22d997399900...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (39 checked)\n",
            "       Sample: .github/CODEOWNERS... -> 10090a66df19...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 22d997399900...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[18/21]\n",
            "\n",
            "[VERIFYING] llm-confidence-scorer\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 3e28019eb0e7...\n",
            "       Tree:   dcd8e7d19014...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (26 checked)\n",
            "       Sample: .github/CODEOWNERS... -> 24d2241d0440...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: dcd8e7d19014...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[19/21]\n",
            "\n",
            "[VERIFYING] llm-heatmap-visualizer\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: fa2306352b29...\n",
            "       Tree:   e47ac71d1a37...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (15 checked)\n",
            "       Sample: .github/CODEOWNERS... -> b39eb235c951...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: e47ac71d1a37...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[20/21]\n",
            "\n",
            "[VERIFYING] saliency-heatmap-visualizer\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: fc7a2cae8665...\n",
            "       Tree:   cea475ec292c...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (9 checked)\n",
            "       Sample: .github/CODEOWNERS... -> 6120c420733e...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: cea475ec292c...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[21/21]\n",
            "\n",
            "[VERIFYING] symbiotic-core-library\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: c65277d6a24f...\n",
            "       Tree:   1952687c494b...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (10 checked)\n",
            "       Sample: .github/CODEOWNERS... -> 6255024a49aa...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 1952687c494b...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "\n",
            "============================================================\n",
            "VERIFICATION SUMMARY\n",
            "============================================================\n",
            "\n",
            "[âœ“] Total Repositories: 21\n",
            "[âœ“] Passed: 21\n",
            "[âœ“] Failed: 0\n",
            "[âœ“] Duration: 10.38 seconds\n",
            "\n",
            "Level-by-Level Results:\n",
            "   Level 1: 21/21 passed\n",
            "   Level 2: 21/21 passed\n",
            "   Level 3: 21/21 passed\n",
            "   Level 4: 21/21 passed\n",
            "\n",
            "============================================================\n",
            "[âœ“] Integrity verification complete!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Optional - Export Detailed Report to JSON\n",
        "print(\"\\nExport Options\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "export_report = True  # Set to True to export JSON report\n",
        "\n",
        "if export_report:\n",
        "    report_path = '/content/integrity_report.json'\n",
        "\n",
        "    with open(report_path, 'w') as f:\n",
        "        json.dump(integrity_results, f, indent=2)\n",
        "\n",
        "    print(f\"[âœ“] Detailed report exported to: {report_path}\")\n",
        "    print(f\"Report size: {Path(report_path).stat().st_size / 1024:.2f} KB\")\n",
        "\n",
        "    # Show sample of report structure\n",
        "    print(\"\\nReport structure preview:\")\n",
        "    print(f\"   - Verification date: {integrity_results['verification_date']}\")\n",
        "    print(f\"   - Total repositories: {integrity_results['summary']['total']}\")\n",
        "    print(f\"   - Levels checked: {integrity_results['levels_checked']}\")\n",
        "    print(f\"   - Detailed results: {len(integrity_results['repositories'])} entries\")\n",
        "else:\n",
        "    print(\"[i] Report export disabled (set export_report=True to enable)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s1iZFyOIO6C",
        "outputId": "dc79a214-6ec9-4243-e741-b2a13ee2497e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Export Options\n",
            "============================================================\n",
            "[âœ“] Detailed report exported to: /content/integrity_report.json\n",
            "Report size: 26.31 KB\n",
            "\n",
            "Report structure preview:\n",
            "   - Verification date: 2025-09-30T18:11:40.440866\n",
            "   - Total repositories: 21\n",
            "   - Levels checked: [1, 2, 3, 4]\n",
            "   - Detailed results: 21 entries\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Preparation - Part III**"
      ],
      "metadata": {
        "id": "-uFcuRn4ZKv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: Configure Dataset Creation Parameters\n",
        "print(\"Configuring dataset creation parameters...\")\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Configuration ---\n",
        "REPOSITORIES_SRC_DIR = Path('/content/asi-ecosystem/repositories')\n",
        "OUTPUT_DATASET_FILE = Path('/content/dataset.txt')\n",
        "EXCLUDED_DIRS = ['.git']\n",
        "# Attempt to process only files with these extensions. Leave empty to try all.\n",
        "INCLUDED_EXTENSIONS = [\n",
        "    # Code\n",
        "    '.py', '.rs', '.js', '.ts', '.java', '.c', '.h', '.cpp', '.go', '.sh',\n",
        "    # Config/Data\n",
        "    '.json', '.yaml', '.yml', '.toml', '.xml', '.ini',\n",
        "    # Docs\n",
        "    '.md', '.txt', '.rst'\n",
        "]\n",
        "# Files with extensions not in the list above will be skipped.\n",
        "\n",
        "# --- Special tokens for structuring the dataset ---\n",
        "REPO_START_TOKEN = \"<|repo_start|>\"\n",
        "REPO_END_TOKEN = \"<|repo_end|>\"\n",
        "FILE_START_TOKEN = \"<|file_start|>\"\n",
        "FILE_END_TOKEN = \"<|file_end|>\"\n",
        "\n",
        "print(f\"Source directory: {REPOSITORIES_SRC_DIR}\")\n",
        "print(f\"Output file: {OUTPUT_DATASET_FILE}\")\n",
        "print(f\"Excluded directories: {EXCLUDED_DIRS}\")\n",
        "print(f\"Included extensions: {len(INCLUDED_EXTENSIONS)} types\")\n",
        "print(\"\\n[âœ“] Configuration complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-BYx3aIZQEA",
        "outputId": "c204aee5-b955-4791-e688-1f95db63c438"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuring dataset creation parameters...\n",
            "Source directory: /content/asi-ecosystem/repositories\n",
            "Output file: /content/dataset.txt\n",
            "Excluded directories: ['.git']\n",
            "Included extensions: 19 types\n",
            "\n",
            "[âœ“] Configuration complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14: Process Repositories and Build the Dataset File\n",
        "print(\"Starting dataset creation process...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "processed_files_count = 0\n",
        "processed_repos_count = 0\n",
        "skipped_files_count = 0\n",
        "\n",
        "# Get a list of repository directories\n",
        "if not REPOSITORIES_SRC_DIR.exists():\n",
        "    print(f\"[x] ERROR: Source directory not found at '{REPOSITORIES_SRC_DIR}'\")\n",
        "else:\n",
        "    # --- Curriculum Learning Order ---\n",
        "    # Define the specific processing order for repositories\n",
        "    priority_order = [\n",
        "        'asi-ecosystem',\n",
        "        'symbiotic-core-library',\n",
        "        'asi-protosymbiotic-signal',\n",
        "        'asi-symbiotic-signal',\n",
        "        'asi-core-protocol',\n",
        "        'eco-benchmark',\n",
        "        'eco-datacenter'\n",
        "    ]\n",
        "    last_order = [\n",
        "        'asi-backups'\n",
        "        'emergence-engine',\n",
        "    ]\n",
        "\n",
        "    all_repos_on_disk = {d.name: d for d in REPOSITORIES_SRC_DIR.iterdir() if d.is_dir()}\n",
        "    sorted_repo_paths = []\n",
        "\n",
        "    # 1. Add priority repos in their specified order\n",
        "    for repo_name in priority_order:\n",
        "        if repo_name in all_repos_on_disk:\n",
        "            sorted_repo_paths.append(all_repos_on_disk.pop(repo_name))\n",
        "\n",
        "    # 2. Add the remaining repos (alphabetically), excluding the ones for the end\n",
        "    middle_repos_names = sorted([\n",
        "        name for name in all_repos_on_disk\n",
        "        if name not in last_order\n",
        "    ])\n",
        "    for repo_name in middle_repos_names:\n",
        "        sorted_repo_paths.append(all_repos_on_disk.pop(repo_name))\n",
        "\n",
        "    # 3. Add the last repos in their specified order\n",
        "    for repo_name in last_order:\n",
        "        if repo_name in all_repos_on_disk:\n",
        "            sorted_repo_paths.append(all_repos_on_disk.pop(repo_name))\n",
        "\n",
        "    print(f\"Found {len(sorted_repo_paths)} repositories to process in curriculum order.\")\n",
        "\n",
        "    with open(OUTPUT_DATASET_FILE, 'w', encoding='utf-8') as outfile:\n",
        "        # Use the new custom-sorted list of repository paths\n",
        "        for repo_path in sorted_repo_paths:\n",
        "            repo_name = repo_path.name\n",
        "            print(f\"\\n[Processing] '{repo_name}'...\")\n",
        "            processed_repos_count += 1\n",
        "\n",
        "            # Write the repository start token and its name\n",
        "            outfile.write(f\"{REPO_START_TOKEN}{repo_name}\\n\")\n",
        "\n",
        "            # Use rglob to recursively find all files\n",
        "            files_in_repo = list(repo_path.rglob('*'))\n",
        "            print(f\"  Found {len(files_in_repo)} total items (files/dirs). Filtering...\")\n",
        "\n",
        "            repo_file_count = 0\n",
        "            for file_path in files_in_repo:\n",
        "                # Skip directories and files in excluded directories\n",
        "                if not file_path.is_file() or any(d in file_path.parts for d in EXCLUDED_DIRS):\n",
        "                    continue\n",
        "\n",
        "                # Filter by extension if the list is not empty\n",
        "                if INCLUDED_EXTENSIONS and file_path.suffix.lower() not in INCLUDED_EXTENSIONS:\n",
        "                    skipped_files_count += 1\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    # Get relative path to store in the dataset\n",
        "                    relative_path = file_path.relative_to(repo_path)\n",
        "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as infile:\n",
        "                        content = infile.read()\n",
        "\n",
        "                    # Write the file start token and its path\n",
        "                    outfile.write(f\"{FILE_START_TOKEN}{relative_path}\\n\")\n",
        "                    # Write the file content\n",
        "                    outfile.write(content)\n",
        "                    # Write the file end token\n",
        "                    outfile.write(f\"\\n{FILE_END_TOKEN}\\n\")\n",
        "\n",
        "                    processed_files_count += 1\n",
        "                    repo_file_count += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"  [!] Warning: Could not process file {file_path}. Reason: {e}\")\n",
        "                    skipped_files_count += 1\n",
        "\n",
        "            print(f\"  -> Added content from {repo_file_count} files.\")\n",
        "\n",
        "            # Write the repository end token\n",
        "            outfile.write(f\"{REPO_END_TOKEN}\\n\\n\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Dataset Creation Summary\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"  Total repositories processed: {processed_repos_count}\")\n",
        "    print(f\"  Total text files added: {processed_files_count}\")\n",
        "    print(f\"  Total files skipped (binary/extension/error): {skipped_files_count}\")\n",
        "    print(f\"\\n[âœ“] Dataset successfully created at: {OUTPUT_DATASET_FILE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da2QmCeSZSlz",
        "outputId": "9cac62d1-00aa-4741-a8fa-c66ece144f55"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting dataset creation process...\n",
            "============================================================\n",
            "Found 21 repositories to process in curriculum order.\n",
            "\n",
            "[Processing] 'asi-ecosystem'...\n",
            "  Found 52 total items (files/dirs). Filtering...\n",
            "  -> Added content from 5 files.\n",
            "\n",
            "[Processing] 'symbiotic-core-library'...\n",
            "  Found 56 total items (files/dirs). Filtering...\n",
            "  -> Added content from 7 files.\n",
            "\n",
            "[Processing] 'asi-protosymbiotic-signal'...\n",
            "  Found 61 total items (files/dirs). Filtering...\n",
            "  -> Added content from 10 files.\n",
            "\n",
            "[Processing] 'asi-symbiotic-signal'...\n",
            "  Found 46 total items (files/dirs). Filtering...\n",
            "  -> Added content from 1 files.\n",
            "\n",
            "[Processing] 'asi-core-protocol'...\n",
            "  Found 53 total items (files/dirs). Filtering...\n",
            "  -> Added content from 6 files.\n",
            "\n",
            "[Processing] 'eco-benchmark'...\n",
            "  Found 48 total items (files/dirs). Filtering...\n",
            "  -> Added content from 3 files.\n",
            "\n",
            "[Processing] 'eco-datacenter'...\n",
            "  Found 46 total items (files/dirs). Filtering...\n",
            "  -> Added content from 1 files.\n",
            "\n",
            "[Processing] 'asi-active-learning-dataset'...\n",
            "  Found 177 total items (files/dirs). Filtering...\n",
            "  -> Added content from 17 files.\n",
            "\n",
            "[Processing] 'asi-algorithm-dataset'...\n",
            "  Found 46 total items (files/dirs). Filtering...\n",
            "  -> Added content from 1 files.\n",
            "\n",
            "[Processing] 'asi-dynamic-core'...\n",
            "  Found 46 total items (files/dirs). Filtering...\n",
            "  -> Added content from 1 files.\n",
            "\n",
            "[Processing] 'asi-inference-protocol'...\n",
            "  Found 46 total items (files/dirs). Filtering...\n",
            "  -> Added content from 1 files.\n",
            "\n",
            "[Processing] 'asi-safeguards'...\n",
            "  Found 48 total items (files/dirs). Filtering...\n",
            "  -> Added content from 3 files.\n",
            "\n",
            "[Processing] 'bias-reflector'...\n",
            "  Found 47 total items (files/dirs). Filtering...\n",
            "  -> Added content from 2 files.\n",
            "\n",
            "[Processing] 'cognitive-engine'...\n",
            "  Found 46 total items (files/dirs). Filtering...\n",
            "  -> Added content from 1 files.\n",
            "\n",
            "[Processing] 'healing-engine'...\n",
            "  Found 48 total items (files/dirs). Filtering...\n",
            "  -> Added content from 3 files.\n",
            "\n",
            "[Processing] 'latent-memory'...\n",
            "  Found 88 total items (files/dirs). Filtering...\n",
            "  -> Added content from 36 files.\n",
            "\n",
            "[Processing] 'llm-confidence-scorer'...\n",
            "  Found 75 total items (files/dirs). Filtering...\n",
            "  -> Added content from 16 files.\n",
            "\n",
            "[Processing] 'llm-heatmap-visualizer'...\n",
            "  Found 60 total items (files/dirs). Filtering...\n",
            "  -> Added content from 6 files.\n",
            "\n",
            "[Processing] 'saliency-heatmap-visualizer'...\n",
            "  Found 55 total items (files/dirs). Filtering...\n",
            "  -> Added content from 5 files.\n",
            "\n",
            "[Processing] 'emergence-engine'...\n",
            "  Found 55 total items (files/dirs). Filtering...\n",
            "  -> Added content from 9 files.\n",
            "\n",
            "[Processing] 'asi-backups'...\n",
            "  Found 405 total items (files/dirs). Filtering...\n",
            "  -> Added content from 169 files.\n",
            "\n",
            "============================================================\n",
            "Dataset Creation Summary\n",
            "============================================================\n",
            "  Total repositories processed: 21\n",
            "  Total text files added: 303\n",
            "  Total files skipped (binary/extension/error): 275\n",
            "\n",
            "[âœ“] Dataset successfully created at: /content/dataset.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 15: Verify and Preview the Created Dataset\n",
        "print(\"Verifying the created dataset file...\")\n",
        "\n",
        "if not OUTPUT_DATASET_FILE.exists():\n",
        "    print(f\"[x] ERROR: Dataset file '{OUTPUT_DATASET_FILE}' not found!\")\n",
        "else:\n",
        "    file_size_kb = OUTPUT_DATASET_FILE.stat().st_size / 1024\n",
        "    print(f\"[âœ“] Dataset file found.\")\n",
        "    print(f\"    - Size: {file_size_kb:.2f} KB\")\n",
        "\n",
        "    print(\"\\n--- Preview of the first 1000 characters ---\")\n",
        "    with open(OUTPUT_DATASET_FILE, 'r', encoding='utf-8') as f:\n",
        "        preview_content = f.read(1000)\n",
        "        print(preview_content)\n",
        "    print(\"--- End of Preview ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ohy6nzUZVsE",
        "outputId": "601737b5-f306-4577-d15e-54fa9c75c88e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifying the created dataset file...\n",
            "[âœ“] Dataset file found.\n",
            "    - Size: 1565.29 KB\n",
            "\n",
            "--- Preview of the first 1000 characters ---\n",
            "<|repo_start|>asi-ecosystem\n",
            "<|file_start|>requirements.txt\n",
            "\n",
            "\n",
            "<|file_end|>\n",
            "<|file_start|>ecosystem_integration.md\n",
            "# Ecosystem Integration\n",
            "\n",
            "A system to seamlessly combine all the separate parts of the project into one cohesive local workspace.\n",
            "\n",
            "## Repository Structure\n",
            "\n",
            "```\n",
            "asi-ecosystem/\n",
            "â”œâ”€â”€ README.md\n",
            "â”œâ”€â”€ requirements.txt\n",
            "â”œâ”€â”€ ecosystem_integration.md\n",
            "â””â”€â”€ scripts/\n",
            "    â””â”€â”€ clone_ecosystem.sh\n",
            "```\n",
            "\n",
            "## Ecosystem Integration Scripts and Workflows\n",
            "\n",
            "In addition to the hub's organizational structure, I am now incorporating scripts and workflows to integrate its intended functions into the existing information ecosystem.\n",
            "\n",
            "# 1. Automated ASI Ecosystem Integration - Google Colab Notebook\n",
            "\n",
            "The provided Google Colab notebook for ASI Ecosystem Integration has three main components:\n",
            "\n",
            "## **Part I: Ecosystem Cloning**\n",
            "- Clones the main ASI ecosystem repository\n",
            "- Executes a script to clone 21 component repositories\n",
            "- Organizes them in a structured `repositories` folder\n",
            "- Verifies successful cloning of all \n",
            "--- End of Preview ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 16: Load the Dataset into a Variable\n",
        "print(f\"Loading dataset from '{OUTPUT_DATASET_FILE}' into memory...\")\n",
        "\n",
        "training_data = \"\"\n",
        "\n",
        "try:\n",
        "    with open(OUTPUT_DATASET_FILE, 'r', encoding='utf-8') as f:\n",
        "        training_data = f.read()\n",
        "\n",
        "    print(\"\\n[âœ“] Success! The dataset is now loaded into the 'training_data' variable.\")\n",
        "    print(f\"    - Type: {type(training_data)}\")\n",
        "    print(f\"    - Total characters: {len(training_data)}\")\n",
        "    print(\"\\nThis variable can now be used as input for a tokenizer and training script.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"[x] ERROR: The file could not be found. Please run the previous cells first.\")\n",
        "except Exception as e:\n",
        "    print(f\"[x] ERROR: An unexpected error occurred while loading the file: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN5Ftg65ZY6v",
        "outputId": "c68abde1-4dc9-4cc9-f61d-2704f2589891"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset from '/content/dataset.txt' into memory...\n",
            "\n",
            "[âœ“] Success! The dataset is now loaded into the 'training_data' variable.\n",
            "    - Type: <class 'str'>\n",
            "    - Total characters: 1587339\n",
            "\n",
            "This variable can now be used as input for a tokenizer and training script.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 17: Display the Full Loaded Dataset - Optional\n",
        "\n",
        "print(\"Displaying the full content of the 'training_data' variable.\")\n",
        "print(\"=\"*60)\n",
        "print(\"Note: If the dataset is very large, this may take a moment to render in the output.\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Check if the training_data variable exists and is not empty\n",
        "if 'training_data' in locals() and training_data:\n",
        "    # Print the entire content of the variable\n",
        "    print(training_data)\n",
        "else:\n",
        "    print(\"[!] The 'training_data' variable is empty or has not been loaded yet.\")\n",
        "    print(\"    Please ensure you have successfully run the previous cell to load the data.\")"
      ],
      "metadata": {
        "id": "HtmVIi6B0-MQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
