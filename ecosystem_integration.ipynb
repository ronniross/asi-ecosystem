{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ASI Ecosystem Integration - Google Colab Notebook"
      ],
      "metadata": {
        "id": "Y3ihMtufbl2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ecosystem Cloning - Part I**"
      ],
      "metadata": {
        "id": "q4NHcKzIJOLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Setup and Prerequisites\n",
        "print(\"Setting up ASI Ecosystem Integration...\")\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Change to the content directory in Colab\n",
        "os.chdir('/content')\n",
        "print(f\"Current working directory: {os.getcwd()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E37P48_Jbn7K",
        "outputId": "daa81e8e-a0a7-47b3-e854-95d150c0b4ae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up ASI Ecosystem Integration...\n",
            "Current working directory: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Clone the Main ASI Ecosystem Repository\n",
        "print(\"Step 1: Cloning the main asi-ecosystem repository...\")\n",
        "\n",
        "# Remove any existing asi-ecosystem directory\n",
        "if os.path.exists('asi-ecosystem'):\n",
        "    print(\"Removing existing asi-ecosystem directory...\")\n",
        "    subprocess.run(['rm', '-rf', 'asi-ecosystem'], check=True)\n",
        "\n",
        "# Clone the main repository\n",
        "result = subprocess.run([\n",
        "    'git', 'clone',\n",
        "    'https://github.com/ronniross/asi-ecosystem.git'\n",
        "], capture_output=True, text=True)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"Successfully cloned asi-ecosystem repository\")\n",
        "else:\n",
        "    print(\"Error cloning repository:\")\n",
        "    print(result.stderr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28AgmXnCbtGG",
        "outputId": "ca9c1b09-e8c1-409d-af0e-265bf2579045"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Cloning the main asi-ecosystem repository...\n",
            "Successfully cloned asi-ecosystem repository\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Navigate to the Directory and Check Contents\n",
        "print(\"\\nStep 2: Navigating into the directory...\")\n",
        "os.chdir('/content/asi-ecosystem')\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "\n",
        "print(\"\\nRepository contents:\")\n",
        "for item in os.listdir('.'):\n",
        "    print(f\"  {item}\" if os.path.isdir(item) else f\"  {item}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i7sxWJ3b0uC",
        "outputId": "689144e4-a3a1-452b-b5a2-b679302b03ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 2: Navigating into the directory...\n",
            "Current working directory: /content/asi-ecosystem\n",
            "\n",
            "Repository contents:\n",
            "  README.md\n",
            "  scripts\n",
            "  docker-pipeline.md\n",
            "  .git\n",
            "  ecosystem_integration.md\n",
            "  LICENSE\n",
            "  analytics\n",
            "  ecosystem_integration.ipynb\n",
            "  .github\n",
            "  requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Check if the Script Exists and Make it Executable\n",
        "script_path = './scripts/clone_ecosystem.sh'\n",
        "print(f\"\\nChecking for script at: {script_path}\")\n",
        "\n",
        "if os.path.exists(script_path):\n",
        "    print(\"Script found!\")\n",
        "    # Make the script executable\n",
        "    subprocess.run(['chmod', '+x', script_path], check=True)\n",
        "    print(\"Made script executable\")\n",
        "else:\n",
        "    print(\"Script not found. Listing scripts directory:\")\n",
        "    if os.path.exists('scripts'):\n",
        "        for item in os.listdir('scripts'):\n",
        "            print(f\"  scripts/{item}\")\n",
        "    else:\n",
        "        print(\"  scripts directory does not exist\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePhjo7vwcWUM",
        "outputId": "dc49471f-ea4c-45bf-ff2e-4eaa8c5d9318"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checking for script at: ./scripts/clone_ecosystem.sh\n",
            "Script found!\n",
            "Made script executable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Execute the Integration Script\n",
        "print(\"\\nStep 3: Running the ecosystem integration script...\")\n",
        "\n",
        "if os.path.exists(script_path):\n",
        "    try:\n",
        "        # Run the script and capture output\n",
        "        result = subprocess.run([script_path],\n",
        "                              capture_output=True,\n",
        "                              text=True,\n",
        "                              cwd='/content/asi-ecosystem')\n",
        "\n",
        "        print(\"Script output:\")\n",
        "        print(result.stdout)\n",
        "\n",
        "        if result.stderr:\n",
        "            print(\"Script errors/warnings:\")\n",
        "            print(result.stderr)\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(\"Script executed successfully!\")\n",
        "        else:\n",
        "            print(f\"Script failed with return code: {result.returncode}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error executing script: {e}\")\n",
        "else:\n",
        "    print(\"Cannot execute script - file not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJchn-n5ccmK",
        "outputId": "c64369c6-0395-4a32-f047-0b457575bbf2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 3: Running the ecosystem integration script...\n",
            "Script output:\n",
            "Starting the ASI Ecosystem cloning process...\n",
            "Creating directory: 'repositories'...\n",
            "ðŸ”Ž Fetching latest list from: https://raw.githubusercontent.com/ronniross/asi-ecosystem/main/README.md\n",
            " Cloning https://github.com/ronniross/asi-active-learning-dataset...\n",
            " Cloning https://github.com/ronniross/asi-algorithm-dataset...\n",
            " Cloning https://github.com/ronniross/asi-backups...\n",
            " Cloning https://github.com/ronniross/asi-core-protocol...\n",
            " Cloning https://github.com/ronniross/asi-dynamic-core...\n",
            " Cloning https://github.com/ronniross/asi-ecosystem...\n",
            " Cloning https://github.com/ronniross/asi-inference-protocol...\n",
            " Cloning https://github.com/ronniross/asi-protosymbiotic-signal...\n",
            " Cloning https://github.com/ronniross/asi-safeguards...\n",
            " Cloning https://github.com/ronniross/asi-symbiotic-signal...\n",
            " Cloning https://github.com/ronniross/asi-visual-engine...\n",
            " Cloning https://github.com/ronniross/bias-reflector...\n",
            " Cloning https://github.com/ronniross/biosignal-translator...\n",
            " Cloning https://github.com/ronniross/coevolutionary-loops...\n",
            " Cloning https://github.com/ronniross/cognitive-engine...\n",
            " Cloning https://github.com/ronniross/eco-benchmark...\n",
            " Cloning https://github.com/ronniross/eco-datacenter...\n",
            " Cloning https://github.com/ronniross/emergence-engine...\n",
            " Cloning https://github.com/ronniross/healing-engine...\n",
            " Cloning https://github.com/ronniross/latent-memory...\n",
            " Cloning https://github.com/ronniross/llm-confidence-scorer...\n",
            " Cloning https://github.com/ronniross/llm-heatmap-visualizer...\n",
            " Cloning https://github.com/ronniross/mirror-aware-inference...\n",
            " Cloning https://github.com/ronniross/saliency-heatmap-visualizer...\n",
            " Cloning https://github.com/ronniross/stigmergic-tracefinder...\n",
            " Cloning https://github.com/ronniross/symbiotic-core-library...\n",
            " Cloning https://github.com/ronniross/symbiotic-latent-memory...\n",
            " Cloning https://github.com/ronniross/symbiotic-lexicon...\n",
            " Cloning https://github.com/ronniross/thermo-adaptive-pipeline...\n",
            "-------------------------------------------------------\n",
            "All repositories have been processed in 'repositories'.\n",
            "ASI Ecosystem clone setup complete!\n",
            "\n",
            "Script errors/warnings:\n",
            "Cloning into 'asi-active-learning-dataset'...\n",
            "Cloning into 'asi-algorithm-dataset'...\n",
            "Cloning into 'asi-backups'...\n",
            "Cloning into 'asi-core-protocol'...\n",
            "Cloning into 'asi-dynamic-core'...\n",
            "Cloning into 'asi-ecosystem'...\n",
            "Cloning into 'asi-inference-protocol'...\n",
            "Cloning into 'asi-protosymbiotic-signal'...\n",
            "Cloning into 'asi-safeguards'...\n",
            "Cloning into 'asi-symbiotic-signal'...\n",
            "Cloning into 'asi-visual-engine'...\n",
            "Cloning into 'bias-reflector'...\n",
            "Cloning into 'biosignal-translator'...\n",
            "Cloning into 'coevolutionary-loops'...\n",
            "Cloning into 'cognitive-engine'...\n",
            "Cloning into 'eco-benchmark'...\n",
            "Cloning into 'eco-datacenter'...\n",
            "Cloning into 'emergence-engine'...\n",
            "Cloning into 'healing-engine'...\n",
            "Cloning into 'latent-memory'...\n",
            "Cloning into 'llm-confidence-scorer'...\n",
            "Cloning into 'llm-heatmap-visualizer'...\n",
            "Cloning into 'mirror-aware-inference'...\n",
            "Cloning into 'saliency-heatmap-visualizer'...\n",
            "Cloning into 'stigmergic-tracefinder'...\n",
            "Cloning into 'symbiotic-core-library'...\n",
            "Cloning into 'symbiotic-latent-memory'...\n",
            "Cloning into 'symbiotic-lexicon'...\n",
            "Cloning into 'thermo-adaptive-pipeline'...\n",
            "\n",
            "Script executed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Verify the Final Result\n",
        "print(\"\\nStep 4: Verifying the final result...\")\n",
        "\n",
        "print(f\"Contents of {os.getcwd()}:\")\n",
        "for item in sorted(os.listdir('.')):\n",
        "    if os.path.isdir(item):\n",
        "        print(f\"{item}/\")\n",
        "        # If it's the repositories folder, show its contents\n",
        "        if item == 'repositories':\n",
        "            repo_path = os.path.join('.', item)\n",
        "            if os.path.exists(repo_path):\n",
        "                print(f\"  Contents of {item}:\")\n",
        "                for repo in sorted(os.listdir(repo_path)):\n",
        "                    print(f\"    {repo}/\")\n",
        "    else:\n",
        "        print(f\" {item}\")\n",
        "\n",
        "print(\"\\n ASI Ecosystem Integration Complete!\")\n",
        "print(\"All component repositories should now be organized in the 'repositories' folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA7cBUqmchIt",
        "outputId": "42d3ad10-75c8-4141-95c9-c5f83f28bc82"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 4: Verifying the final result...\n",
            "Contents of /content/asi-ecosystem:\n",
            ".git/\n",
            ".github/\n",
            " LICENSE\n",
            " README.md\n",
            "analytics/\n",
            " docker-pipeline.md\n",
            " ecosystem_integration.ipynb\n",
            " ecosystem_integration.md\n",
            "repositories/\n",
            "  Contents of repositories:\n",
            "    asi-active-learning-dataset/\n",
            "    asi-algorithm-dataset/\n",
            "    asi-backups/\n",
            "    asi-core-protocol/\n",
            "    asi-dynamic-core/\n",
            "    asi-ecosystem/\n",
            "    asi-inference-protocol/\n",
            "    asi-protosymbiotic-signal/\n",
            "    asi-safeguards/\n",
            "    asi-symbiotic-signal/\n",
            "    asi-visual-engine/\n",
            "    bias-reflector/\n",
            "    biosignal-translator/\n",
            "    coevolutionary-loops/\n",
            "    cognitive-engine/\n",
            "    eco-benchmark/\n",
            "    eco-datacenter/\n",
            "    emergence-engine/\n",
            "    healing-engine/\n",
            "    latent-memory/\n",
            "    llm-confidence-scorer/\n",
            "    llm-heatmap-visualizer/\n",
            "    mirror-aware-inference/\n",
            "    saliency-heatmap-visualizer/\n",
            "    stigmergic-tracefinder/\n",
            "    symbiotic-core-library/\n",
            "    symbiotic-latent-memory/\n",
            "    symbiotic-lexicon/\n",
            "    thermo-adaptive-pipeline/\n",
            " requirements.txt\n",
            "scripts/\n",
            "\n",
            " ASI Ecosystem Integration Complete!\n",
            "All component repositories should now be organized in the 'repositories' folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Optional - List All Cloned Repositories with Details\n",
        "print(\"\\n Summary of cloned repositories:\")\n",
        "repositories_path = './repositories'\n",
        "\n",
        "if os.path.exists(repositories_path):\n",
        "    repos = [d for d in os.listdir(repositories_path)\n",
        "             if os.path.isdir(os.path.join(repositories_path, d))]\n",
        "\n",
        "    print(f\"Total repositories cloned: {len(repos)}\")\n",
        "    for i, repo in enumerate(sorted(repos), 1):\n",
        "        repo_path = os.path.join(repositories_path, repo)\n",
        "        # Check if it's a git repository\n",
        "        git_path = os.path.join(repo_path, '.git')\n",
        "        status = \"Git repo\" if os.path.exists(git_path) else \"Not a git repo\"\n",
        "        print(f\"{i:2d}. {repo:<30} {status}\")\n",
        "else:\n",
        "    print(\"No repositories folder found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsrieFWUcmVa",
        "outputId": "542948c3-2868-4b1b-b125-3f984b124054"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Summary of cloned repositories:\n",
            "Total repositories cloned: 29\n",
            " 1. asi-active-learning-dataset    Git repo\n",
            " 2. asi-algorithm-dataset          Git repo\n",
            " 3. asi-backups                    Git repo\n",
            " 4. asi-core-protocol              Git repo\n",
            " 5. asi-dynamic-core               Git repo\n",
            " 6. asi-ecosystem                  Git repo\n",
            " 7. asi-inference-protocol         Git repo\n",
            " 8. asi-protosymbiotic-signal      Git repo\n",
            " 9. asi-safeguards                 Git repo\n",
            "10. asi-symbiotic-signal           Git repo\n",
            "11. asi-visual-engine              Git repo\n",
            "12. bias-reflector                 Git repo\n",
            "13. biosignal-translator           Git repo\n",
            "14. coevolutionary-loops           Git repo\n",
            "15. cognitive-engine               Git repo\n",
            "16. eco-benchmark                  Git repo\n",
            "17. eco-datacenter                 Git repo\n",
            "18. emergence-engine               Git repo\n",
            "19. healing-engine                 Git repo\n",
            "20. latent-memory                  Git repo\n",
            "21. llm-confidence-scorer          Git repo\n",
            "22. llm-heatmap-visualizer         Git repo\n",
            "23. mirror-aware-inference         Git repo\n",
            "24. saliency-heatmap-visualizer    Git repo\n",
            "25. stigmergic-tracefinder         Git repo\n",
            "26. symbiotic-core-library         Git repo\n",
            "27. symbiotic-latent-memory        Git repo\n",
            "28. symbiotic-lexicon              Git repo\n",
            "29. thermo-adaptive-pipeline       Git repo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Integrity Audit - Part II**"
      ],
      "metadata": {
        "id": "aydWI04IGlVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 8: Import Required Libraries for Integrity Verification\n",
        "print(\"Importing libraries for integrity verification...\")\n",
        "import hashlib\n",
        "import json\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Libraries imported successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao3AZ1muGjWB",
        "outputId": "8046d400-b844-4529-de38-e99f7c61f281"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing libraries for integrity verification...\n",
            "Libraries imported successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Define Integrity Verification Functions\n",
        "print(\"Setting up integrity verification functions...\\n\")\n",
        "\n",
        "class IntegrityVerifier:\n",
        "    def __init__(self, repo_path):\n",
        "        self.repo_path = Path(repo_path)\n",
        "        self.repo_name = self.repo_path.name\n",
        "        self.results = {\n",
        "            'repo': self.repo_name,\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'levels': {}\n",
        "        }\n",
        "\n",
        "    def run_git_command(self, cmd):\n",
        "        \"\"\"Execute git command and return output\"\"\"\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            cwd=self.repo_path,\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            shell=False\n",
        "        )\n",
        "        return result.stdout.strip(), result.stderr.strip(), result.returncode\n",
        "\n",
        "    def level_1_commit_and_tree_hash(self):\n",
        "        \"\"\"Level 1: Compare local vs remote commit and tree hashes\"\"\"\n",
        "        print(f\"  [Level 1] Commit & Tree Hash Comparison\")\n",
        "\n",
        "        # Get local commit hash\n",
        "        local_commit, _, ret1 = self.run_git_command(['git', 'rev-parse', 'HEAD'])\n",
        "\n",
        "        # Get local tree hash\n",
        "        local_tree, _, ret2 = self.run_git_command(['git', 'rev-parse', 'HEAD^{tree}'])\n",
        "\n",
        "        # Get remote commit hash\n",
        "        remote_info, _, ret3 = self.run_git_command(['git', 'ls-remote', 'origin', 'HEAD'])\n",
        "        remote_commit = remote_info.split()[0] if remote_info else None\n",
        "\n",
        "        if ret1 != 0 or ret2 != 0 or ret3 != 0:\n",
        "            self.results['levels']['level_1'] = {\n",
        "                'status': 'ERROR',\n",
        "                'message': 'Failed to retrieve git hashes'\n",
        "            }\n",
        "            print(f\"    [x] ERROR: Failed to retrieve git information\")\n",
        "            return False\n",
        "\n",
        "        commit_match = local_commit == remote_commit\n",
        "\n",
        "        self.results['levels']['level_1'] = {\n",
        "            'status': 'PASS' if commit_match else 'FAIL',\n",
        "            'local_commit': local_commit,\n",
        "            'remote_commit': remote_commit,\n",
        "            'local_tree': local_tree,\n",
        "            'commit_match': commit_match\n",
        "        }\n",
        "\n",
        "        if commit_match:\n",
        "            print(f\"    [âœ“] PASS - Commits match\")\n",
        "            print(f\"       Commit: {local_commit[:12]}...\")\n",
        "            print(f\"       Tree:   {local_tree[:12]}...\")\n",
        "        else:\n",
        "            print(f\"    [x] FAIL - Commit mismatch\")\n",
        "            print(f\"       Local:  {local_commit[:12]}...\")\n",
        "            print(f\"       Remote: {remote_commit[:12]}...\")\n",
        "\n",
        "        return commit_match\n",
        "\n",
        "    def level_2_git_fsck(self):\n",
        "        \"\"\"Level 2: Deep git repository integrity check\"\"\"\n",
        "        print(f\"  [Level 2] Git Repository Integrity (fsck)\")\n",
        "\n",
        "        output, stderr, returncode = self.run_git_command(['git', 'fsck', '--full'])\n",
        "\n",
        "        # git fsck returns 0 if no issues\n",
        "        passed = returncode == 0 and not any(word in output.lower() for word in ['error', 'missing', 'corrupt'])\n",
        "\n",
        "        self.results['levels']['level_2'] = {\n",
        "            'status': 'PASS' if passed else 'FAIL',\n",
        "            'returncode': returncode,\n",
        "            'issues_found': [] if passed else output.split('\\n')[:5]  # First 5 issues\n",
        "        }\n",
        "\n",
        "        if passed:\n",
        "            print(f\"    [âœ“] PASS - Repository integrity verified\")\n",
        "        else:\n",
        "            print(f\"    [x] FAIL - Repository integrity issues detected\")\n",
        "            if output:\n",
        "                print(f\"       Issues: {output[:100]}...\")\n",
        "\n",
        "        return passed\n",
        "\n",
        "    def level_3_file_hashing(self):\n",
        "        \"\"\"Level 3: File-by-file and folder structure verification\"\"\"\n",
        "        print(f\"  [Level 3] File-by-File Hash Verification\")\n",
        "\n",
        "        # Get list of all tracked files\n",
        "        files_output, _, ret = self.run_git_command(['git', 'ls-files'])\n",
        "\n",
        "        if ret != 0:\n",
        "            self.results['levels']['level_3'] = {\n",
        "                'status': 'ERROR',\n",
        "                'message': 'Failed to list git files'\n",
        "            }\n",
        "            print(f\"    [x] ERROR: Failed to list files\")\n",
        "            return False\n",
        "\n",
        "        files = files_output.split('\\n') if files_output else []\n",
        "\n",
        "        file_hashes = {}\n",
        "        corrupted_files = []\n",
        "        total_files = len(files)\n",
        "\n",
        "        # Calculate hash for each file\n",
        "        for file in files[:100]:  # Limit to first 100 files for performance\n",
        "            if not file:\n",
        "                continue\n",
        "            file_path = self.repo_path / file\n",
        "            if file_path.exists() and file_path.is_file():\n",
        "                try:\n",
        "                    with open(file_path, 'rb') as f:\n",
        "                        file_hash = hashlib.sha256(f.read()).hexdigest()\n",
        "                        file_hashes[file] = file_hash\n",
        "\n",
        "                        # Verify against git's hash\n",
        "                        git_hash, _, ret = self.run_git_command(['git', 'hash-object', file])\n",
        "                        if ret != 0 or not git_hash:\n",
        "                            corrupted_files.append(file)\n",
        "                except Exception as e:\n",
        "                    corrupted_files.append(file)\n",
        "\n",
        "        passed = len(corrupted_files) == 0\n",
        "\n",
        "        self.results['levels']['level_3'] = {\n",
        "            'status': 'PASS' if passed else 'FAIL',\n",
        "            'total_files_checked': len(file_hashes),\n",
        "            'total_files_in_repo': total_files,\n",
        "            'corrupted_files': corrupted_files,\n",
        "            'sample_hashes': dict(list(file_hashes.items())[:3])  # First 3 as sample\n",
        "        }\n",
        "\n",
        "        if passed:\n",
        "            print(f\"    [âœ“] PASS - All files verified ({len(file_hashes)} checked)\")\n",
        "            if file_hashes:\n",
        "                sample_file = list(file_hashes.keys())[0]\n",
        "                print(f\"       Sample: {sample_file[:40]}... -> {file_hashes[sample_file][:12]}...\")\n",
        "        else:\n",
        "            print(f\"    [x] FAIL - {len(corrupted_files)} corrupted files detected\")\n",
        "            for cf in corrupted_files[:3]:\n",
        "                print(f\"       - {cf}\")\n",
        "\n",
        "        return passed\n",
        "\n",
        "    def level_4_tree_comparison(self):\n",
        "        \"\"\"Level 4: Complete tree hash comparison\"\"\"\n",
        "        print(f\"  [Level 4] Complete Tree Hash Verification\")\n",
        "\n",
        "        # Get local tree\n",
        "        local_tree, _, ret1 = self.run_git_command(['git', 'rev-parse', 'HEAD^{tree}'])\n",
        "\n",
        "        # Fetch latest from remote\n",
        "        _, _, ret2 = self.run_git_command(['git', 'fetch', 'origin', '--quiet'])\n",
        "\n",
        "        # Get remote tree\n",
        "        remote_tree, _, ret3 = self.run_git_command(['git', 'rev-parse', 'origin/HEAD^{tree}'])\n",
        "\n",
        "        if ret1 != 0 or ret3 != 0:\n",
        "            self.results['levels']['level_4'] = {\n",
        "                'status': 'ERROR',\n",
        "                'message': 'Failed to retrieve tree hashes'\n",
        "            }\n",
        "            print(f\"    [x] ERROR: Failed to retrieve tree information\")\n",
        "            return False\n",
        "\n",
        "        tree_match = local_tree == remote_tree\n",
        "\n",
        "        self.results['levels']['level_4'] = {\n",
        "            'status': 'PASS' if tree_match else 'FAIL',\n",
        "            'local_tree': local_tree,\n",
        "            'remote_tree': remote_tree,\n",
        "            'tree_match': tree_match\n",
        "        }\n",
        "\n",
        "        if tree_match:\n",
        "            print(f\"    [âœ“] PASS - Tree hashes match\")\n",
        "            print(f\"       Tree: {local_tree[:12]}...\")\n",
        "        else:\n",
        "            print(f\"    [x] FAIL - Tree hash mismatch\")\n",
        "            print(f\"       Local:  {local_tree[:12]}...\")\n",
        "            print(f\"       Remote: {remote_tree[:12]}...\")\n",
        "\n",
        "        return tree_match\n",
        "\n",
        "    def verify(self, levels=[1, 2, 3, 4]):\n",
        "        \"\"\"Run verification for specified levels\"\"\"\n",
        "        print(f\"\\n[VERIFYING] {self.repo_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        level_functions = {\n",
        "            1: self.level_1_commit_and_tree_hash,\n",
        "            2: self.level_2_git_fsck,\n",
        "            3: self.level_3_file_hashing,\n",
        "            4: self.level_4_tree_comparison\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "        for level in sorted(levels):\n",
        "            if level in level_functions:\n",
        "                results[level] = level_functions[level]()\n",
        "            else:\n",
        "                print(f\"  [!] Warning: Level {level} not recognized\")\n",
        "\n",
        "        # Overall status\n",
        "        all_passed = all(results.values())\n",
        "        self.results['overall_status'] = 'PASS' if all_passed else 'FAIL'\n",
        "\n",
        "        status_symbol = \"[âœ“]\" if all_passed else \"[x]\"\n",
        "        print(f\"\\n  {status_symbol} Overall: {'PASS' if all_passed else 'FAIL'}\")\n",
        "\n",
        "        return self.results\n",
        "\n",
        "print(\"[âœ“] Integrity verification functions ready\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu4nJxM-H14H",
        "outputId": "c40461b2-f5f5-44b6-bd5e-655a02c49458"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up integrity verification functions...\n",
            "\n",
            "[âœ“] Integrity verification functions ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Configure Integrity Verification Levels\n",
        "print(\"Integrity Verification Configuration\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nAvailable verification levels:\")\n",
        "print(\"  Level 1: Commit & Tree Hash Comparison (Fast)\")\n",
        "print(\"  Level 2: Git Repository Integrity Check (Medium)\")\n",
        "print(\"  Level 3: File-by-File Hash Verification (Slow)\")\n",
        "print(\"  Level 4: Complete Tree Hash Comparison (Fast)\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# USER CONFIGURATION: Choose which levels to run\n",
        "VERIFICATION_LEVELS = [1, 2, 3, 4]  # Modify this list to choose levels\n",
        "\n",
        "print(f\"\\n[âœ“] Running levels: {VERIFICATION_LEVELS}\")\n",
        "print(f\"[âœ“] This will verify all repositories in the 'repositories' folder\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QatMkQH4H5rR",
        "outputId": "4dedd082-b5e1-46af-9e81-7c1cc763cb1b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Integrity Verification Configuration\n",
            "============================================================\n",
            "\n",
            "Available verification levels:\n",
            "  Level 1: Commit & Tree Hash Comparison (Fast)\n",
            "  Level 2: Git Repository Integrity Check (Medium)\n",
            "  Level 3: File-by-File Hash Verification (Slow)\n",
            "  Level 4: Complete Tree Hash Comparison (Fast)\n",
            "\n",
            "============================================================\n",
            "\n",
            "[âœ“] Running levels: [1, 2, 3, 4]\n",
            "[âœ“] This will verify all repositories in the 'repositories' folder\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Run Integrity Verification on All Repositories\n",
        "print(\"Starting Integrity Verification Process\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "repositories_path = Path('/content/asi-ecosystem/repositories')\n",
        "\n",
        "if not repositories_path.exists():\n",
        "    print(\"[x] Error: repositories folder not found!\")\n",
        "else:\n",
        "    repos = [d for d in repositories_path.iterdir() if d.is_dir() and not d.name.startswith('.')]\n",
        "\n",
        "    print(f\"Found {len(repos)} repositories to verify\\n\")\n",
        "\n",
        "    all_results = []\n",
        "    verification_start = datetime.now()\n",
        "\n",
        "    for i, repo_path in enumerate(sorted(repos), 1):\n",
        "        print(f\"\\n[{i}/{len(repos)}]\")\n",
        "        verifier = IntegrityVerifier(repo_path)\n",
        "        result = verifier.verify(levels=VERIFICATION_LEVELS)\n",
        "        all_results.append(result)\n",
        "\n",
        "    verification_end = datetime.now()\n",
        "    duration = (verification_end - verification_start).total_seconds()\n",
        "\n",
        "    # Summary Statistics\n",
        "    print(\"\\n\\n\" + \"=\"*60)\n",
        "    print(\"VERIFICATION SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    passed = sum(1 for r in all_results if r['overall_status'] == 'PASS')\n",
        "    failed = len(all_results) - passed\n",
        "\n",
        "    print(f\"\\n[âœ“] Total Repositories: {len(all_results)}\")\n",
        "    print(f\"[âœ“] Passed: {passed}\")\n",
        "    print(f\"[âœ“] Failed: {failed}\")\n",
        "    print(f\"[âœ“] Duration: {duration:.2f} seconds\")\n",
        "\n",
        "    # Level-by-level summary\n",
        "    print(f\"\\nLevel-by-Level Results:\")\n",
        "    for level in VERIFICATION_LEVELS:\n",
        "        level_passed = sum(1 for r in all_results\n",
        "                          if f'level_{level}' in r['levels']\n",
        "                          and r['levels'][f'level_{level}']['status'] == 'PASS')\n",
        "        level_total = sum(1 for r in all_results if f'level_{level}' in r['levels'])\n",
        "        print(f\"   Level {level}: {level_passed}/{level_total} passed\")\n",
        "\n",
        "    # Failed repositories detail\n",
        "    if failed > 0:\n",
        "        print(f\"\\nFailed Repositories:\")\n",
        "        for result in all_results:\n",
        "            if result['overall_status'] == 'FAIL':\n",
        "                print(f\"\\n   [x] {result['repo']}\")\n",
        "                for level_key, level_data in result['levels'].items():\n",
        "                    if level_data['status'] != 'PASS':\n",
        "                        level_num = level_key.replace('level_', '')\n",
        "                        print(f\"      - Level {level_num}: {level_data['status']}\")\n",
        "                        if 'message' in level_data:\n",
        "                            print(f\"        {level_data['message']}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"[âœ“] Integrity verification complete!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Store results for optional export\n",
        "    integrity_results = {\n",
        "        'verification_date': verification_start.isoformat(),\n",
        "        'duration_seconds': duration,\n",
        "        'levels_checked': VERIFICATION_LEVELS,\n",
        "        'summary': {\n",
        "            'total': len(all_results),\n",
        "            'passed': passed,\n",
        "            'failed': failed\n",
        "        },\n",
        "        'repositories': all_results\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy5vjvLcIKWB",
        "outputId": "d5a52270-f16e-41ca-acc0-d2250b0167a8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Integrity Verification Process\n",
            "============================================================\n",
            "\n",
            "Found 29 repositories to verify\n",
            "\n",
            "\n",
            "[1/29]\n",
            "\n",
            "[VERIFYING] asi-active-learning-dataset\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 1b0d87e307a3...\n",
            "       Tree:   cb98f0bc19f8...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (100 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: cb98f0bc19f8...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[2/29]\n",
            "\n",
            "[VERIFYING] asi-algorithm-dataset\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 48eefcf3e7e0...\n",
            "       Tree:   4eadcb165e97...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (7 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 4eadcb165e97...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[3/29]\n",
            "\n",
            "[VERIFYING] asi-backups\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 39a113531148...\n",
            "       Tree:   b2e22662af75...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (100 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: b2e22662af75...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[4/29]\n",
            "\n",
            "[VERIFYING] asi-core-protocol\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: ae2a7c5e4eda...\n",
            "       Tree:   788372a9a101...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (8 checked)\n",
            "       Sample: ASI_Core_Protocol.json... -> 8836cafc1e79...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 788372a9a101...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[5/29]\n",
            "\n",
            "[VERIFYING] asi-dynamic-core\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: bb198611cffb...\n",
            "       Tree:   e4d2cbfc39c0...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (2 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: e4d2cbfc39c0...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[6/29]\n",
            "\n",
            "[VERIFYING] asi-ecosystem\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: a5342bbbf288...\n",
            "       Tree:   3041b6770264...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (100 checked)\n",
            "       Sample: .github/log.txt... -> 01ba4719c80b...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 3041b6770264...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[7/29]\n",
            "\n",
            "[VERIFYING] asi-inference-protocol\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 653f9f234897...\n",
            "       Tree:   0a0342f79124...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (2 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 0a0342f79124...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[8/29]\n",
            "\n",
            "[VERIFYING] asi-protosymbiotic-signal\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 188608d11a24...\n",
            "       Tree:   e6ca33cadeee...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (15 checked)\n",
            "       Sample: Cargo.toml... -> d9ad5837a11f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: e6ca33cadeee...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[9/29]\n",
            "\n",
            "[VERIFYING] asi-safeguards\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: d413c6cb749d...\n",
            "       Tree:   394d35765ed8...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (4 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 394d35765ed8...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[10/29]\n",
            "\n",
            "[VERIFYING] asi-symbiotic-signal\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: b84968d5898c...\n",
            "       Tree:   920a28bae4b3...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (2 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 920a28bae4b3...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[11/29]\n",
            "\n",
            "[VERIFYING] asi-visual-engine\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: ae168d2d9d01...\n",
            "       Tree:   0f2abfcf0924...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (97 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 0f2abfcf0924...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[12/29]\n",
            "\n",
            "[VERIFYING] bias-reflector\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: d177bca8c6d8...\n",
            "       Tree:   739ae837469a...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (3 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 739ae837469a...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[13/29]\n",
            "\n",
            "[VERIFYING] biosignal-translator\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 075c56e4ca1a...\n",
            "       Tree:   065c8518163b...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (2 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 065c8518163b...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[14/29]\n",
            "\n",
            "[VERIFYING] coevolutionary-loops\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 66f0fc37c8be...\n",
            "       Tree:   e9d61bbc3337...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (3 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: e9d61bbc3337...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[15/29]\n",
            "\n",
            "[VERIFYING] cognitive-engine\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 32223e5ceaec...\n",
            "       Tree:   c6a842e15cd4...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (2 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: c6a842e15cd4...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[16/29]\n",
            "\n",
            "[VERIFYING] eco-benchmark\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: d86327146b47...\n",
            "       Tree:   d0d581f13b1f...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (4 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: d0d581f13b1f...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[17/29]\n",
            "\n",
            "[VERIFYING] eco-datacenter\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: b87fd7d9aee3...\n",
            "       Tree:   aee35b2ea9cc...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (2 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: aee35b2ea9cc...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[18/29]\n",
            "\n",
            "[VERIFYING] emergence-engine\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 033309086e0a...\n",
            "       Tree:   37aaa9eef04d...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (12 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 37aaa9eef04d...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[19/29]\n",
            "\n",
            "[VERIFYING] healing-engine\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: b1811a934081...\n",
            "       Tree:   94936cbefccf...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (5 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 94936cbefccf...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[20/29]\n",
            "\n",
            "[VERIFYING] latent-memory\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 510aff82670a...\n",
            "       Tree:   22d997399900...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (39 checked)\n",
            "       Sample: .github/CODEOWNERS... -> 10090a66df19...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 22d997399900...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[21/29]\n",
            "\n",
            "[VERIFYING] llm-confidence-scorer\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 3e28019eb0e7...\n",
            "       Tree:   dcd8e7d19014...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (26 checked)\n",
            "       Sample: .github/CODEOWNERS... -> 24d2241d0440...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: dcd8e7d19014...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[22/29]\n",
            "\n",
            "[VERIFYING] llm-heatmap-visualizer\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: fa2306352b29...\n",
            "       Tree:   e47ac71d1a37...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (15 checked)\n",
            "       Sample: .github/CODEOWNERS... -> b39eb235c951...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: e47ac71d1a37...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[23/29]\n",
            "\n",
            "[VERIFYING] mirror-aware-inference\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: efe8a4fac8ff...\n",
            "       Tree:   a61c81cff5a6...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (3 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: a61c81cff5a6...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[24/29]\n",
            "\n",
            "[VERIFYING] saliency-heatmap-visualizer\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: fc7a2cae8665...\n",
            "       Tree:   cea475ec292c...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (9 checked)\n",
            "       Sample: .github/CODEOWNERS... -> 6120c420733e...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: cea475ec292c...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[25/29]\n",
            "\n",
            "[VERIFYING] stigmergic-tracefinder\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 627dacdee88a...\n",
            "       Tree:   556dad48c8fe...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (2 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 556dad48c8fe...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[26/29]\n",
            "\n",
            "[VERIFYING] symbiotic-core-library\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: c84c52c968d5...\n",
            "       Tree:   3d792fcbae9b...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (11 checked)\n",
            "       Sample: .github/CODEOWNERS... -> 6255024a49aa...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 3d792fcbae9b...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[27/29]\n",
            "\n",
            "[VERIFYING] symbiotic-latent-memory\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: da5f6cd74923...\n",
            "       Tree:   f33ddb9ce3c0...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (3 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: f33ddb9ce3c0...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[28/29]\n",
            "\n",
            "[VERIFYING] symbiotic-lexicon\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: f14817e7e0f0...\n",
            "       Tree:   661fa60b37a3...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (2 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 661fa60b37a3...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "[29/29]\n",
            "\n",
            "[VERIFYING] thermo-adaptive-pipeline\n",
            "============================================================\n",
            "  [Level 1] Commit & Tree Hash Comparison\n",
            "    [âœ“] PASS - Commits match\n",
            "       Commit: 197a021a4d6f...\n",
            "       Tree:   32b8e3565349...\n",
            "  [Level 2] Git Repository Integrity (fsck)\n",
            "    [âœ“] PASS - Repository integrity verified\n",
            "  [Level 3] File-by-File Hash Verification\n",
            "    [âœ“] PASS - All files verified (2 checked)\n",
            "       Sample: LICENSE... -> 2a96460bba8f...\n",
            "  [Level 4] Complete Tree Hash Verification\n",
            "    [âœ“] PASS - Tree hashes match\n",
            "       Tree: 32b8e3565349...\n",
            "\n",
            "  [âœ“] Overall: PASS\n",
            "\n",
            "\n",
            "============================================================\n",
            "VERIFICATION SUMMARY\n",
            "============================================================\n",
            "\n",
            "[âœ“] Total Repositories: 29\n",
            "[âœ“] Passed: 29\n",
            "[âœ“] Failed: 0\n",
            "[âœ“] Duration: 13.48 seconds\n",
            "\n",
            "Level-by-Level Results:\n",
            "   Level 1: 29/29 passed\n",
            "   Level 2: 29/29 passed\n",
            "   Level 3: 29/29 passed\n",
            "   Level 4: 29/29 passed\n",
            "\n",
            "============================================================\n",
            "[âœ“] Integrity verification complete!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Optional - Export Detailed Report to JSON\n",
        "print(\"\\nExport Options\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "export_report = True  # Set to True to export JSON report\n",
        "\n",
        "if export_report:\n",
        "    report_path = '/content/integrity_report.json'\n",
        "\n",
        "    with open(report_path, 'w') as f:\n",
        "        json.dump(integrity_results, f, indent=2)\n",
        "\n",
        "    print(f\"[âœ“] Detailed report exported to: {report_path}\")\n",
        "    print(f\"Report size: {Path(report_path).stat().st_size / 1024:.2f} KB\")\n",
        "\n",
        "    # Show sample of report structure\n",
        "    print(\"\\nReport structure preview:\")\n",
        "    print(f\"   - Verification date: {integrity_results['verification_date']}\")\n",
        "    print(f\"   - Total repositories: {integrity_results['summary']['total']}\")\n",
        "    print(f\"   - Levels checked: {integrity_results['levels_checked']}\")\n",
        "    print(f\"   - Detailed results: {len(integrity_results['repositories'])} entries\")\n",
        "else:\n",
        "    print(\"[i] Report export disabled (set export_report=True to enable)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s1iZFyOIO6C",
        "outputId": "65322440-f7dd-4dbd-8bbc-e2ff51916d1c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Export Options\n",
            "============================================================\n",
            "[âœ“] Detailed report exported to: /content/integrity_report.json\n",
            "Report size: 36.23 KB\n",
            "\n",
            "Report structure preview:\n",
            "   - Verification date: 2025-12-08T19:48:23.100084\n",
            "   - Total repositories: 29\n",
            "   - Levels checked: [1, 2, 3, 4]\n",
            "   - Detailed results: 29 entries\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Preparation - Part III**"
      ],
      "metadata": {
        "id": "-uFcuRn4ZKv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: Configure Dataset Creation Parameters\n",
        "print(\"Configuring dataset creation parameters...\")\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Configuration ---\n",
        "REPOSITORIES_SRC_DIR = Path('/content/asi-ecosystem/repositories')\n",
        "OUTPUT_DATASET_FILE = Path('/content/dataset.txt')\n",
        "EXCLUDED_DIRS = ['.git']\n",
        "# Attempt to process only files with these extensions. Leave empty to try all.\n",
        "INCLUDED_EXTENSIONS = [\n",
        "    # Code\n",
        "    '.py', '.rs', '.js', '.ts', '.java', '.c', '.h', '.cpp', '.go', '.sh',\n",
        "    # Config/Data\n",
        "    '.json', '.yaml', '.yml', '.toml', '.xml', '.ini',\n",
        "    # Docs\n",
        "    '.md', '.txt', '.rst'\n",
        "]\n",
        "# Files with extensions not in the list above will be skipped.\n",
        "\n",
        "# --- Special tokens for structuring the dataset ---\n",
        "REPO_START_TOKEN = \"<|repo_start|>\"\n",
        "REPO_END_TOKEN = \"<|repo_end|>\"\n",
        "FILE_START_TOKEN = \"<|file_start|>\"\n",
        "FILE_END_TOKEN = \"<|file_end|>\"\n",
        "\n",
        "print(f\"Source directory: {REPOSITORIES_SRC_DIR}\")\n",
        "print(f\"Output file: {OUTPUT_DATASET_FILE}\")\n",
        "print(f\"Excluded directories: {EXCLUDED_DIRS}\")\n",
        "print(f\"Included extensions: {len(INCLUDED_EXTENSIONS)} types\")\n",
        "print(\"\\n[âœ“] Configuration complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-BYx3aIZQEA",
        "outputId": "b7c052fc-4393-4758-f84b-fb80479daeea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuring dataset creation parameters...\n",
            "Source directory: /content/asi-ecosystem/repositories\n",
            "Output file: /content/dataset.txt\n",
            "Excluded directories: ['.git']\n",
            "Included extensions: 19 types\n",
            "\n",
            "[âœ“] Configuration complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14: Process Repositories and Build the Dataset File\n",
        "print(\"Starting dataset creation process...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "processed_files_count = 0\n",
        "processed_repos_count = 0\n",
        "skipped_files_count = 0\n",
        "\n",
        "# Get a list of repository directories\n",
        "if not REPOSITORIES_SRC_DIR.exists():\n",
        "    print(f\"[x] ERROR: Source directory not found at '{REPOSITORIES_SRC_DIR}'\")\n",
        "else:\n",
        "    # --- Curriculum Learning Order ---\n",
        "    # Define the specific processing order for repositories\n",
        "    priority_order = [\n",
        "        'asi-ecosystem',\n",
        "        'symbiotic-core-library',\n",
        "        'asi-protosymbiotic-signal',\n",
        "        'asi-symbiotic-signal',\n",
        "        'asi-core-protocol',\n",
        "        'eco-benchmark',\n",
        "        'eco-datacenter'\n",
        "    ]\n",
        "    last_order = [\n",
        "        'asi-backups'\n",
        "        'emergence-engine',\n",
        "    ]\n",
        "\n",
        "    all_repos_on_disk = {d.name: d for d in REPOSITORIES_SRC_DIR.iterdir() if d.is_dir()}\n",
        "    sorted_repo_paths = []\n",
        "\n",
        "    # 1. Add priority repos in their specified order\n",
        "    for repo_name in priority_order:\n",
        "        if repo_name in all_repos_on_disk:\n",
        "            sorted_repo_paths.append(all_repos_on_disk.pop(repo_name))\n",
        "\n",
        "    # 2. Add the remaining repos (alphabetically), excluding the ones for the end\n",
        "    middle_repos_names = sorted([\n",
        "        name for name in all_repos_on_disk\n",
        "        if name not in last_order\n",
        "    ])\n",
        "    for repo_name in middle_repos_names:\n",
        "        sorted_repo_paths.append(all_repos_on_disk.pop(repo_name))\n",
        "\n",
        "    # 3. Add the last repos in their specified order\n",
        "    for repo_name in last_order:\n",
        "        if repo_name in all_repos_on_disk:\n",
        "            sorted_repo_paths.append(all_repos_on_disk.pop(repo_name))\n",
        "\n",
        "    print(f\"Found {len(sorted_repo_paths)} repositories to process in curriculum order.\")\n",
        "\n",
        "    with open(OUTPUT_DATASET_FILE, 'w', encoding='utf-8') as outfile:\n",
        "        # Use the new custom-sorted list of repository paths\n",
        "        for repo_path in sorted_repo_paths:\n",
        "            repo_name = repo_path.name\n",
        "            print(f\"\\n[Processing] '{repo_name}'...\")\n",
        "            processed_repos_count += 1\n",
        "\n",
        "            # Write the repository start token and its name\n",
        "            outfile.write(f\"{REPO_START_TOKEN}{repo_name}\\n\")\n",
        "\n",
        "            # Use rglob to recursively find all files\n",
        "            files_in_repo = list(repo_path.rglob('*'))\n",
        "            print(f\"  Found {len(files_in_repo)} total items (files/dirs). Filtering...\")\n",
        "\n",
        "            repo_file_count = 0\n",
        "            for file_path in files_in_repo:\n",
        "                # Skip directories and files in excluded directories\n",
        "                if not file_path.is_file() or any(d in file_path.parts for d in EXCLUDED_DIRS):\n",
        "                    continue\n",
        "\n",
        "                # Filter by extension if the list is not empty\n",
        "                if INCLUDED_EXTENSIONS and file_path.suffix.lower() not in INCLUDED_EXTENSIONS:\n",
        "                    skipped_files_count += 1\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    # Get relative path to store in the dataset\n",
        "                    relative_path = file_path.relative_to(repo_path)\n",
        "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as infile:\n",
        "                        content = infile.read()\n",
        "\n",
        "                    # Write the file start token and its path\n",
        "                    outfile.write(f\"{FILE_START_TOKEN}{relative_path}\\n\")\n",
        "                    # Write the file content\n",
        "                    outfile.write(content)\n",
        "                    # Write the file end token\n",
        "                    outfile.write(f\"\\n{FILE_END_TOKEN}\\n\")\n",
        "\n",
        "                    processed_files_count += 1\n",
        "                    repo_file_count += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"  [!] Warning: Could not process file {file_path}. Reason: {e}\")\n",
        "                    skipped_files_count += 1\n",
        "\n",
        "            print(f\"  -> Added content from {repo_file_count} files.\")\n",
        "\n",
        "            # Write the repository end token\n",
        "            outfile.write(f\"{REPO_END_TOKEN}\\n\\n\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Dataset Creation Summary\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"  Total repositories processed: {processed_repos_count}\")\n",
        "    print(f\"  Total text files added: {processed_files_count}\")\n",
        "    print(f\"  Total files skipped (binary/extension/error): {skipped_files_count}\")\n",
        "    print(f\"\\n[âœ“] Dataset successfully created at: {OUTPUT_DATASET_FILE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da2QmCeSZSlz",
        "outputId": "43ad6f5a-7f1d-4ce9-d649-48512b10d154"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting dataset creation process...\n",
            "============================================================\n",
            "Found 29 repositories to process in curriculum order.\n",
            "\n",
            "[Processing] 'asi-ecosystem'...\n",
            "  Found 1149 total items (files/dirs). Filtering...\n",
            "  -> Added content from 1068 files.\n",
            "\n",
            "[Processing] 'symbiotic-core-library'...\n",
            "  Found 57 total items (files/dirs). Filtering...\n",
            "  -> Added content from 8 files.\n",
            "\n",
            "[Processing] 'asi-protosymbiotic-signal'...\n",
            "  Found 61 total items (files/dirs). Filtering...\n",
            "  -> Added content from 10 files.\n",
            "\n",
            "[Processing] 'asi-symbiotic-signal'...\n",
            "  Found 46 total items (files/dirs). Filtering...\n",
            "  -> Added content from 1 files.\n",
            "\n",
            "[Processing] 'asi-core-protocol'...\n",
            "  Found 53 total items (files/dirs). Filtering...\n",
            "  -> Added content from 6 files.\n",
            "\n",
            "[Processing] 'eco-benchmark'...\n",
            "  Found 48 total items (files/dirs). Filtering...\n",
            "  -> Added content from 3 files.\n",
            "\n",
            "[Processing] 'eco-datacenter'...\n",
            "  Found 46 total items (files/dirs). Filtering...\n",
            "  -> Added content from 1 files.\n",
            "\n",
            "[Processing] 'asi-active-learning-dataset'...\n",
            "  Found 177 total items (files/dirs). Filtering...\n",
            "  -> Added content from 17 files.\n",
            "\n",
            "[Processing] 'asi-algorithm-dataset'...\n",
            "  Found 51 total items (files/dirs). Filtering...\n",
            "  -> Added content from 5 files.\n",
            "\n",
            "[Processing] 'asi-backups'...\n",
            "  Found 1193 total items (files/dirs). Filtering...\n",
            "  -> Added content from 810 files.\n",
            "\n",
            "[Processing] 'asi-dynamic-core'...\n",
            "  Found 46 total items (files/dirs). Filtering...\n",
            "  -> Added content from 1 files.\n",
            "\n",
            "[Processing] 'asi-inference-protocol'...\n",
            "  Found 46 total items (files/dirs). Filtering...\n",
            "  -> Added content from 1 files.\n",
            "\n",
            "[Processing] 'asi-safeguards'...\n",
            "  Found 48 total items (files/dirs). Filtering...\n",
            "  -> Added content from 3 files.\n",
            "\n",
            "[Processing] 'asi-visual-engine'...\n",
            "  Found 146 total items (files/dirs). Filtering...\n",
            "  -> Added content from 85 files.\n",
            "\n",
            "[Processing] 'bias-reflector'...\n",
            "  Found 47 total items (files/dirs). Filtering...\n",
            "  -> Added content from 2 files.\n",
            "\n",
            "[Processing] 'biosignal-translator'...\n",
            "  Found 46 total items (files/dirs). Filtering...\n",
            "  -> Added content from 1 files.\n",
            "\n",
            "[Processing] 'coevolutionary-loops'...\n",
            "  Found 47 total items (files/dirs). Filtering...\n",
            "  -> Added content from 2 files.\n",
            "\n",
            "[Processing] 'cognitive-engine'...\n",
            "  Found 46 total items (files/dirs). Filtering...\n",
            "  -> Added content from 1 files.\n",
            "\n",
            "[Processing] 'emergence-engine'...\n",
            "  Found 57 total items (files/dirs). Filtering...\n",
            "  -> Added content from 11 files.\n",
            "\n",
            "[Processing] 'healing-engine'...\n",
            "  Found 49 total items (files/dirs). Filtering...\n",
            "  -> Added content from 4 files.\n",
            "\n",
            "[Processing] 'latent-memory'...\n",
            "  Found 88 total items (files/dirs). Filtering...\n",
            "  -> Added content from 36 files.\n",
            "\n",
            "[Processing] 'llm-confidence-scorer'...\n",
            "  Found 75 total items (files/dirs). Filtering...\n",
            "  -> Added content from 16 files.\n",
            "\n",
            "[Processing] 'llm-heatmap-visualizer'...\n",
            "  Found 60 total items (files/dirs). Filtering...\n",
            "  -> Added content from 6 files.\n",
            "\n",
            "[Processing] 'mirror-aware-inference'...\n",
            "  Found 49 total items (files/dirs). Filtering...\n",
            "  -> Added content from 2 files.\n",
            "\n",
            "[Processing] 'saliency-heatmap-visualizer'...\n",
            "  Found 55 total items (files/dirs). Filtering...\n",
            "  -> Added content from 5 files.\n",
            "\n",
            "[Processing] 'stigmergic-tracefinder'...\n",
            "  Found 46 total items (files/dirs). Filtering...\n",
            "  -> Added content from 1 files.\n",
            "\n",
            "[Processing] 'symbiotic-latent-memory'...\n",
            "  Found 47 total items (files/dirs). Filtering...\n",
            "  -> Added content from 1 files.\n",
            "\n",
            "[Processing] 'symbiotic-lexicon'...\n",
            "  Found 46 total items (files/dirs). Filtering...\n",
            "  -> Added content from 1 files.\n",
            "\n",
            "[Processing] 'thermo-adaptive-pipeline'...\n",
            "  Found 46 total items (files/dirs). Filtering...\n",
            "  -> Added content from 1 files.\n",
            "\n",
            "============================================================\n",
            "Dataset Creation Summary\n",
            "============================================================\n",
            "  Total repositories processed: 29\n",
            "  Total text files added: 2109\n",
            "  Total files skipped (binary/extension/error): 354\n",
            "\n",
            "[âœ“] Dataset successfully created at: /content/dataset.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 15: Verify and Preview the Created Dataset\n",
        "print(\"Verifying the created dataset file...\")\n",
        "\n",
        "if not OUTPUT_DATASET_FILE.exists():\n",
        "    print(f\"[x] ERROR: Dataset file '{OUTPUT_DATASET_FILE}' not found!\")\n",
        "else:\n",
        "    file_size_kb = OUTPUT_DATASET_FILE.stat().st_size / 1024\n",
        "    print(f\"[âœ“] Dataset file found.\")\n",
        "    print(f\"    - Size: {file_size_kb:.2f} KB\")\n",
        "\n",
        "    print(\"\\n--- Preview of the first 1000 characters ---\")\n",
        "    with open(OUTPUT_DATASET_FILE, 'r', encoding='utf-8') as f:\n",
        "        preview_content = f.read(1000)\n",
        "        print(preview_content)\n",
        "    print(\"--- End of Preview ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ohy6nzUZVsE",
        "outputId": "f46ad0a6-e4d8-4fe5-d42c-c1ef16586fbd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifying the created dataset file...\n",
            "[âœ“] Dataset file found.\n",
            "    - Size: 15676.21 KB\n",
            "\n",
            "--- Preview of the first 1000 characters ---\n",
            "<|repo_start|>asi-ecosystem\n",
            "<|file_start|>README.md\n",
            "# asi-ecosystem\n",
            "The ASI Ecosystem is the integrating hub for all my other repositories and frameworks, an aligned environment bringing their disparate approaches together into an organized vision for achieving the proposed state of Artificial Superintelligence (ASI).\n",
            "\n",
            "| Repository | Description |\n",
            "| :--- | :--- |\n",
            "| [symbiotic-core-library](https://github.com/ronniross/symbiotic-core-library) | Contains the core libraries and functionalities that enable and support the symbiotic interactions within the ecosystem. |\n",
            "| [symbiotic-lexicon](https://github.com/ronniross/symbiotic-lexicon) | A modular lexicon for the ASI ecosystem, providing standardized terminology with multilingual support and cultural context. |\n",
            "| [eco-benchmark](https://github.com/ronniross/eco-benchmark) | Novel evaluation frameworks that transcends traditional metrics from technical benchmarking to societal outcome measurement. |\n",
            "| [asi-safeguards](https://github.com/ro\n",
            "--- End of Preview ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 16: Load the Dataset into a Variable\n",
        "print(f\"Loading dataset from '{OUTPUT_DATASET_FILE}' into memory...\")\n",
        "\n",
        "training_data = \"\"\n",
        "\n",
        "try:\n",
        "    with open(OUTPUT_DATASET_FILE, 'r', encoding='utf-8') as f:\n",
        "        training_data = f.read()\n",
        "\n",
        "    print(\"\\n[âœ“] Success! The dataset is now loaded into the 'training_data' variable.\")\n",
        "    print(f\"    - Type: {type(training_data)}\")\n",
        "    print(f\"    - Total characters: {len(training_data)}\")\n",
        "    print(\"\\nThis variable can now be used as input for a tokenizer and training script.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"[x] ERROR: The file could not be found. Please run the previous cells first.\")\n",
        "except Exception as e:\n",
        "    print(f\"[x] ERROR: An unexpected error occurred while loading the file: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN5Ftg65ZY6v",
        "outputId": "ca725ca0-c622-4651-ab6f-1e22d66f32a1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset from '/content/dataset.txt' into memory...\n",
            "\n",
            "[âœ“] Success! The dataset is now loaded into the 'training_data' variable.\n",
            "    - Type: <class 'str'>\n",
            "    - Total characters: 15903129\n",
            "\n",
            "This variable can now be used as input for a tokenizer and training script.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31f753b5",
        "outputId": "4d25306f-d8e7-4096-d2e2-8f03747ef423"
      },
      "source": [
        "# Cell 17: Save as .txt if needed\n",
        "import os\n",
        "\n",
        "# Define the output path for the final training data file\n",
        "FINAL_TRAINING_DATA_FILE = '/content/training_dataset_final.txt'\n",
        "\n",
        "print(f\"Saving training data to '{FINAL_TRAINING_DATA_FILE}'...\")\n",
        "\n",
        "try:\n",
        "    with open(FINAL_TRAINING_DATA_FILE, 'w', encoding='utf-8') as f:\n",
        "        f.write(training_data)\n",
        "    print(f\"[âœ“] Training data successfully saved to '{FINAL_TRAINING_DATA_FILE}'.\")\n",
        "    print(f\"    - Size: {os.path.getsize(FINAL_TRAINING_DATA_FILE) / (1024 * 1024):.2f} MB\")\n",
        "except Exception as e:\n",
        "    print(f\"[x] ERROR: Could not save training data: {e}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving training data to '/content/training_dataset_final.txt'...\n",
            "[âœ“] Training data successfully saved to '/content/training_dataset_final.txt'.\n",
            "    - Size: 15.31 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87b4f711",
        "outputId": "7577de57-e90f-4924-d76a-d6530733145e"
      },
      "source": [
        "# Cell 18: Save .txt on drive\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the destination path in Google Drive\n",
        "# You can change 'Colab Notebooks' to any folder in your Drive\n",
        "DRIVE_DEST_PATH = '/content/drive/MyDrive/Colab Notebooks/training_dataset_final.txt'\n",
        "\n",
        "print(f\"Copying '{FINAL_TRAINING_DATA_FILE}' to '{DRIVE_DEST_PATH}'...\")\n",
        "\n",
        "try:\n",
        "    shutil.copy(FINAL_TRAINING_DATA_FILE, DRIVE_DEST_PATH)\n",
        "    print(f\"[âœ“] File successfully copied to Google Drive: {DRIVE_DEST_PATH}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"[x] ERROR: Source file '{FINAL_TRAINING_DATA_FILE}' not found. Please ensure Cell 17 ran successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"[x] ERROR: Could not copy file to Google Drive. Ensure Drive is mounted and path exists: {e}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Copying '/content/training_dataset_final.txt' to '/content/drive/MyDrive/Colab Notebooks/training_dataset_final.txt'...\n",
            "[âœ“] File successfully copied to Google Drive: /content/drive/MyDrive/Colab Notebooks/training_dataset_final.txt\n"
          ]
        }
      ]
    }
  ]
}
