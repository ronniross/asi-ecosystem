name: Track All Repository Clones

on:
  schedule:
    - cron: '33 3 * * *'
  workflow_dispatch:
  push:
    paths:
      - '.github/workflows/track-clones.yml'
      - 'README.md'

jobs:
  track-clones:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # REQUIRED to allow git push

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Initialize tracking system
        run: |
          mkdir -p analytics
          CURRENT_TIMESTAMP=$(TZ='Etc/GMT+3' date '+%Y-%m-%d %H:%M:%S GMT-3')
          
          if [ ! -f analytics/tracking-started.txt ]; then
            echo "First run detected - initializing tracking system"
            echo "$CURRENT_TIMESTAMP" > analytics/tracking-started.txt
            echo "Tracking started: $CURRENT_TIMESTAMP"
            echo "---"
          else
            TRACKING_STARTED=$(cat analytics/tracking-started.txt)
            echo "Tracking system started on: $TRACKING_STARTED"
            echo "Current run: $CURRENT_TIMESTAMP"
            echo "---"
          fi

      - name: Extract repositories from README
        run: |
          # Clean extraction of owner/repo
          grep -oP 'https://github\.com/\K[\w-]+/[\w.-]+' README.md | sort -u > extracted_repos.txt
          echo "Extracted repositories:"
          cat extracted_repos.txt
          echo "---"

      - name: Fetch and record clone data
        env:
          TRAFFIC_TOKEN: ${{ secrets.TRAFFIC_TOKEN }}
        run: |
          TIMESTAMP=$(TZ='Etc/GMT+3' date +%Y-%m-%d_%H-%M-%S)
          READABLE_TIMESTAMP=$(TZ='Etc/GMT+3' date '+%Y-%m-%d %H:%M:%S GMT-3')
          
          # HARDCODED CHECKPOINT - December 6th baseline
          CHECKPOINT_TIMESTAMP="2025-12-06 00:55:13 GMT-3"
          CHECKPOINT_TOTAL=1254
          CHECKPOINT_UNIQUE=966
          
          echo "Processing repositories..."
          echo "Using checkpoint from: $CHECKPOINT_TIMESTAMP"
          echo "Checkpoint totals: $CHECKPOINT_TOTAL total, $CHECKPOINT_UNIQUE unique"
          echo ""
          
          # Initialize Run Deltas (New clones found in THIS run specifically)
          RUN_DELTA_TOTAL=0
          RUN_DELTA_UNIQUE=0
          
          while IFS= read -r REPO_FULL_NAME || [ -n "$REPO_FULL_NAME" ]; do
            [[ -z "$REPO_FULL_NAME" ]] && continue
            
            # Clean potential trailing dots or slashes from regex capture
            REPO_FULL_NAME=$(echo "$REPO_FULL_NAME" | sed 's/[./]*$//')
            
            REPO_OWNER="${REPO_FULL_NAME%/*}"
            REPO_NAME="${REPO_FULL_NAME#*/}"
            
            echo "Fetching data for: $REPO_FULL_NAME"
            
            mkdir -p "analytics/$REPO_NAME"
            
            # API Call with HTTP Code capture
            HTTP_RESPONSE=$(curl -s -w "%{http_code}" -H "Authorization: token $TRAFFIC_TOKEN" "https://api.github.com/repos/$REPO_FULL_NAME/traffic/clones")
            
            # Separate body from status code (last 3 chars are status code)
            HTTP_BODY=${HTTP_RESPONSE:0:${#HTTP_RESPONSE}-3}
            HTTP_STATUS=${HTTP_RESPONSE:${#HTTP_RESPONSE}-3}
            
            if [ "$HTTP_STATUS" != "200" ]; then
                echo "::error::Failed to fetch data for $REPO_FULL_NAME. Status: $HTTP_STATUS"
                echo "API Response: $HTTP_BODY"
                continue
            fi

            # Parse using jq (More robust than grep)
            CURRENT_TOTAL=$(echo "$HTTP_BODY" | jq '.count // 0')
            CURRENT_UNIQUE=$(echo "$HTTP_BODY" | jq '.uniques // 0')
            
            echo "  > API returned: $CURRENT_TOTAL total, $CURRENT_UNIQUE unique"
            
            # --- INDIVIDUAL REPO LOGIC ---
            # 1. Find the most recent file for THIS repo to compare against
            PREVIOUS_FILE=$(ls -t analytics/$REPO_NAME/clones_*.json 2>/dev/null | grep -v "$TIMESTAMP" | head -1)
            
            # 2. Determine previous cumulative values for THIS repo
            if [ -f "$PREVIOUS_FILE" ]; then
              PREVIOUS_API_TOTAL=$(jq '.current_period.total_clones // 0' "$PREVIOUS_FILE")
              PREVIOUS_API_UNIQUE=$(jq '.current_period.unique_clones // 0' "$PREVIOUS_FILE")
              PREVIOUS_CUMULATIVE_TOTAL=$(jq '.cumulative.total_clones // 0' "$PREVIOUS_FILE")
              PREVIOUS_CUMULATIVE_UNIQUE=$(jq '.cumulative.unique_clones // 0' "$PREVIOUS_FILE")
              TRACKING_STARTED=$(jq -r '.tracking_started' "$PREVIOUS_FILE")
              
              echo "  > Previous file found. Cumulative was: $PREVIOUS_CUMULATIVE_TOTAL"
            else
               # Fallback: Check if there is a specific checkpoint file from Dec 6
               CHECKPOINT_FILE=$(ls -t analytics/$REPO_NAME/clones_2025-12-06_*.json 2>/dev/null | head -1)
               
               if [ -f "$CHECKPOINT_FILE" ]; then
                 PREVIOUS_API_TOTAL=0 # Assume reset if we are jumping from checkpoint
                 PREVIOUS_API_UNIQUE=0
                 PREVIOUS_CUMULATIVE_TOTAL=$(jq '.cumulative.total_clones // 0' "$CHECKPOINT_FILE")
                 PREVIOUS_CUMULATIVE_UNIQUE=$(jq '.cumulative.unique_clones // 0' "$CHECKPOINT_FILE")
                 TRACKING_STARTED=$(jq -r '.tracking_started' "$CHECKPOINT_FILE")
                 echo "  > Using Dec 6 Checkpoint. Cumulative was: $PREVIOUS_CUMULATIVE_TOTAL"
               else
                 # New repo or no history
                 PREVIOUS_API_TOTAL=0
                 PREVIOUS_API_UNIQUE=0
                 PREVIOUS_CUMULATIVE_TOTAL=0
                 PREVIOUS_CUMULATIVE_UNIQUE=0
                 TRACKING_STARTED=$(cat analytics/tracking-started.txt)
                 echo "  > No history found. Starting fresh."
               fi
            fi

            # 3. Calculate Deltas (The "Last 24 Hours" Logic)
            if [ $CURRENT_TOTAL -ge $PREVIOUS_API_TOTAL ]; then
              DELTA_TOTAL=$((CURRENT_TOTAL - PREVIOUS_API_TOTAL))
            else
              # Window rolled over, assume all current are new
              DELTA_TOTAL=$CURRENT_TOTAL
            fi
            
            if [ $CURRENT_UNIQUE -ge $PREVIOUS_API_UNIQUE ]; then
              DELTA_UNIQUE=$((CURRENT_UNIQUE - PREVIOUS_API_UNIQUE))
            else
              DELTA_UNIQUE=$CURRENT_UNIQUE
            fi

            # 4. Calculate NEW Cumulative for THIS repo
            NEW_CUMULATIVE_TOTAL=$((PREVIOUS_CUMULATIVE_TOTAL + DELTA_TOTAL))
            NEW_CUMULATIVE_UNIQUE=$((PREVIOUS_CUMULATIVE_UNIQUE + DELTA_UNIQUE))
            
            echo "  > Delta: +$DELTA_TOTAL | New Cumulative: $NEW_CUMULATIVE_TOTAL"
            
            # 5. Add to Global Run Delta
            RUN_DELTA_TOTAL=$((RUN_DELTA_TOTAL + DELTA_TOTAL))
            RUN_DELTA_UNIQUE=$((RUN_DELTA_UNIQUE + DELTA_UNIQUE))
            
            # Save Record for this specific repo
            jq -n \
              --arg repo "$REPO_FULL_NAME" \
              --arg ts "$READABLE_TIMESTAMP" \
              --arg start "$TRACKING_STARTED" \
              --arg checkpoint "$CHECKPOINT_TIMESTAMP" \
              --argjson c_total "$CURRENT_TOTAL" \
              --argjson c_unique "$CURRENT_UNIQUE" \
              --argjson delta_total "$DELTA_TOTAL" \
              --argjson delta_unique "$DELTA_UNIQUE" \
              --argjson cum_total "$NEW_CUMULATIVE_TOTAL" \
              --argjson cum_unique "$NEW_CUMULATIVE_UNIQUE" \
              '{repository: $repo, timestamp: $ts, tracking_started: $start, checkpoint_date: $checkpoint, current_period: {total_clones: $c_total, unique_clones: $c_unique}, delta_since_checkpoint: {total_clones: $delta_total, unique_clones: $delta_unique}, cumulative: {total_clones: $cum_total, unique_clones: $cum_unique}}' > "analytics/$REPO_NAME/clones_$TIMESTAMP.json"
            
            echo "  > Saved record."
            echo ""
            
          done < extracted_repos.txt
          
          # --- CALCULATE ECOSYSTEM TOTALS ---
          # Logic: Load PREVIOUS Ecosystem Total -> Add Sum of Deltas -> Save
          
          LAST_AGGREGATE_FILE=$(ls -t analytics/aggregate_*.json 2>/dev/null | head -1)
          
          if [ -f "$LAST_AGGREGATE_FILE" ]; then
             PREV_ECOSYSTEM_TOTAL=$(jq '.ecosystem_totals.total_clones // 0' "$LAST_AGGREGATE_FILE")
             PREV_ECOSYSTEM_UNIQUE=$(jq '.ecosystem_totals.unique_clones // 0' "$LAST_AGGREGATE_FILE")
          else
             PREV_ECOSYSTEM_TOTAL=0
             PREV_ECOSYSTEM_UNIQUE=0
          fi
          
          # SAFETY: If previous total is inexplicably lower than checkpoint (e.g. the 1250 error), reset to checkpoint
          if [ "$PREV_ECOSYSTEM_TOTAL" -lt "$CHECKPOINT_TOTAL" ]; then
             echo "Detected previous total below baseline. Resetting to checkpoint: $CHECKPOINT_TOTAL"
             PREV_ECOSYSTEM_TOTAL=$CHECKPOINT_TOTAL
          fi
          if [ "$PREV_ECOSYSTEM_UNIQUE" -lt "$CHECKPOINT_UNIQUE" ]; then
             PREV_ECOSYSTEM_UNIQUE=$CHECKPOINT_UNIQUE
          fi
          
          # Calculate Final Totals
          AGGREGATE_TOTAL=$((PREV_ECOSYSTEM_TOTAL + RUN_DELTA_TOTAL))
          AGGREGATE_UNIQUE=$((PREV_ECOSYSTEM_UNIQUE + RUN_DELTA_UNIQUE))
          
          # Save Ecosystem Totals
          jq -n \
            --arg ts "$READABLE_TIMESTAMP" \
            --arg checkpoint "$CHECKPOINT_TIMESTAMP" \
            --argjson checkpoint_total "$CHECKPOINT_TOTAL" \
            --argjson checkpoint_unique "$CHECKPOINT_UNIQUE" \
            --argjson total "$AGGREGATE_TOTAL" \
            --argjson unique "$AGGREGATE_UNIQUE" \
            '{timestamp: $ts, checkpoint_date: $checkpoint, checkpoint_totals: {total_clones: $checkpoint_total, unique_clones: $checkpoint_unique}, ecosystem_totals: {total_clones: $total, unique_clones: $unique}}' > "analytics/aggregate_$TIMESTAMP.json"
          
          echo "====================================="
          echo "Ecosystem-wide Statistics"
          echo "Checkpoint Baseline: $CHECKPOINT_TOTAL"
          echo "Previous Valid Total: $PREV_ECOSYSTEM_TOTAL"
          echo "New Clones (This Run): +$RUN_DELTA_TOTAL"
          echo "FINAL TOTAL: $AGGREGATE_TOTAL"
          echo "FINAL UNIQUE: $AGGREGATE_UNIQUE"

      - name: Commit and push data
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add analytics/
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            COMMIT_TIME=$(TZ='Etc/GMT+3' date '+%Y-%m-%d %H:%M:%S GMT-3')
            git commit -m "Update clone statistics - $COMMIT_TIME"
            git push
          fi
