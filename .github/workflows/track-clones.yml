name: Track All Repository Clones

on:
  schedule:
    - cron: '33 3 * * *'
  workflow_dispatch:
  push:
    paths:
      - '.github/workflows/track-clones.yml'
      - 'README.md'

jobs:
  track-clones:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # REQUIRED to allow git push

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Initialize tracking system
        run: |
          mkdir -p analytics
          CURRENT_TIMESTAMP=$(TZ='Etc/GMT+3' date '+%Y-%m-%d %H:%M:%S GMT-3')
          
          if [ ! -f analytics/tracking-started.txt ]; then
            echo "First run detected - initializing tracking system"
            echo "$CURRENT_TIMESTAMP" > analytics/tracking-started.txt
            echo "Tracking started: $CURRENT_TIMESTAMP"
            echo "---"
          else
            TRACKING_STARTED=$(cat analytics/tracking-started.txt)
            echo "Tracking system started on: $TRACKING_STARTED"
            echo "Current run: $CURRENT_TIMESTAMP"
            echo "---"
          fi

      - name: Extract repositories from README
        run: |
          grep -oP 'https://github\.com/\K[\w-]+/[\w.-]+' README.md | sort -u > extracted_repos.txt
          echo "Extracted repositories:"
          cat extracted_repos.txt
          echo "---"

      - name: Fetch and record clone data
        env:
          TRAFFIC_TOKEN: ${{ secrets.TRAFFIC_TOKEN }}
        run: |
          TIMESTAMP=$(TZ='Etc/GMT+3' date +%Y-%m-%d_%H-%M-%S)
          READABLE_TIMESTAMP=$(TZ='Etc/GMT+3' date '+%Y-%m-%d %H:%M:%S GMT-3')
          
          # HARDCODED CHECKPOINT (Dec 6th Baseline)
          CHECKPOINT_TIMESTAMP="2025-12-06 00:55:13 GMT-3"
          CHECKPOINT_FILE_PATTERN="2025-12-06_00-55-13"
          CHECKPOINT_TOTAL=1254
          CHECKPOINT_UNIQUE=966
          
          echo "Processing repositories..."
          echo "Checkpoint Baseline: $CHECKPOINT_TOTAL total / $CHECKPOINT_UNIQUE unique"
          echo "Checkpoint File Pattern: $CHECKPOINT_FILE_PATTERN"
          echo ""
          
          # Initialize variables to sum up ONLY the new clones from today
          GLOBAL_DAILY_DELTA_TOTAL=0
          GLOBAL_DAILY_DELTA_UNIQUE=0
          
          while IFS= read -r REPO_FULL_NAME || [ -n "$REPO_FULL_NAME" ]; do
            [[ -z "$REPO_FULL_NAME" ]] && continue
            REPO_FULL_NAME=$(echo "$REPO_FULL_NAME" | sed 's/[./]*$//')
            REPO_NAME="${REPO_FULL_NAME#*/}"
            
            echo "Processing: $REPO_FULL_NAME"
            mkdir -p "analytics/$REPO_NAME"
            
            # --- API REQUEST ---
            HTTP_RESPONSE=$(curl -s -w "%{http_code}" -H "Authorization: token $TRAFFIC_TOKEN" "https://api.github.com/repos/$REPO_FULL_NAME/traffic/clones")
            HTTP_BODY=${HTTP_RESPONSE:0:${#HTTP_RESPONSE}-3}
            HTTP_STATUS=${HTTP_RESPONSE:${#HTTP_RESPONSE}-3}
            
            if [ "$HTTP_STATUS" != "200" ]; then
                echo "::error::Failed to fetch $REPO_FULL_NAME. Status: $HTTP_STATUS"
                continue
            fi

            # Current API Window (Last 14 Days)
            CURRENT_API_TOTAL=$(echo "$HTTP_BODY" | jq '.count // 0')
            CURRENT_API_UNIQUE=$(echo "$HTTP_BODY" | jq '.uniques // 0')
            
            echo "  > Current API (14 days): $CURRENT_API_TOTAL total / $CURRENT_API_UNIQUE unique"
            
            # --- FIND CHECKPOINT DATA FOR THIS REPO ---
            CHECKPOINT_FILE="analytics/$REPO_NAME/clones_${CHECKPOINT_FILE_PATTERN}.json"
            
            # Default values
            CHECKPOINT_API_TOTAL=0
            CHECKPOINT_API_UNIQUE=0
            REPO_CHECKPOINT_CUMULATIVE_TOTAL=0
            REPO_CHECKPOINT_CUMULATIVE_UNIQUE=0
            TRACKING_STARTED=$(cat analytics/tracking-started.txt)
            
            if [ -f "$CHECKPOINT_FILE" ]; then
                # This repo existed at checkpoint
                CHECKPOINT_API_TOTAL=$(jq '.current_period.total_clones // 0' "$CHECKPOINT_FILE")
                CHECKPOINT_API_UNIQUE=$(jq '.current_period.unique_clones // 0' "$CHECKPOINT_FILE")
                REPO_CHECKPOINT_CUMULATIVE_TOTAL=$(jq '.cumulative.total_clones // 0' "$CHECKPOINT_FILE")
                REPO_CHECKPOINT_CUMULATIVE_UNIQUE=$(jq '.cumulative.unique_clones // 0' "$CHECKPOINT_FILE")
                echo "  > Found checkpoint data"
                echo "  > Checkpoint API: $CHECKPOINT_API_TOTAL"
                echo "  > Checkpoint Cumulative: $REPO_CHECKPOINT_CUMULATIVE_TOTAL"
            else
                # This is a new repo added after checkpoint
                echo "  > New repo (after checkpoint), no checkpoint data"
            fi
            
            # --- FIND YESTERDAY'S DATA FOR DELTA CALCULATION ---
            # We need yesterday's API reading to calculate today's delta
            YESTERDAY_FILE=$(ls -t analytics/$REPO_NAME/clones_*.json 2>/dev/null | grep -v "$TIMESTAMP" | grep -v "$CHECKPOINT_FILE_PATTERN" | head -1)
            
            YESTERDAY_API_TOTAL=0
            YESTERDAY_API_UNIQUE=0
            
            if [ -f "$YESTERDAY_FILE" ]; then
                # We have yesterday's data
                YESTERDAY_API_TOTAL=$(jq '.current_period.total_clones // 0' "$YESTERDAY_FILE")
                YESTERDAY_API_UNIQUE=$(jq '.current_period.unique_clones // 0' "$YESTERDAY_FILE")
                echo "  > Yesterday's API: $YESTERDAY_API_TOTAL (from $YESTERDAY_FILE)"
            elif [ -f "$CHECKPOINT_FILE" ]; then
                # No yesterday file but we have checkpoint - use checkpoint as yesterday
                YESTERDAY_API_TOTAL=$CHECKPOINT_API_TOTAL
                YESTERDAY_API_UNIQUE=$CHECKPOINT_API_UNIQUE
                echo "  > Using checkpoint as yesterday's data"
            else
                # No data at all - this is first time tracking this repo
                echo "  > First time tracking this repo"
            fi
            
            # --- CALCULATE TODAY'S DELTA ---
            # Delta = Current API - Yesterday's API (or Checkpoint API if no yesterday)
            DAILY_DELTA_TOTAL=0
            DAILY_DELTA_UNIQUE=0
            
            if [ "$CURRENT_API_TOTAL" -gt "$YESTERDAY_API_TOTAL" ]; then
                DAILY_DELTA_TOTAL=$((CURRENT_API_TOTAL - YESTERDAY_API_TOTAL))
                echo "  > Daily Delta: $CURRENT_API_TOTAL - $YESTERDAY_API_TOTAL = +$DAILY_DELTA_TOTAL"
            else
                echo "  > No new clones today (or API window rolled over)"
            fi
            
            if [ "$CURRENT_API_UNIQUE" -gt "$YESTERDAY_API_UNIQUE" ]; then
                DAILY_DELTA_UNIQUE=$((CURRENT_API_UNIQUE - YESTERDAY_API_UNIQUE))
            fi
            
            # --- CALCULATE NEW CUMULATIVE FOR THIS REPO ---
            # New Cumulative = Checkpoint Cumulative + Sum of all daily deltas since checkpoint
            # To get sum of all deltas, we need to find all files after checkpoint
            
            # Start with checkpoint cumulative
            NEW_REPO_CUMULATIVE_TOTAL=$REPO_CHECKPOINT_CUMULATIVE_TOTAL
            NEW_REPO_CUMULATIVE_UNIQUE=$REPO_CHECKPOINT_CUMULATIVE_UNIQUE
            
            # If we have yesterday's file, use its cumulative + today's delta
            if [ -f "$YESTERDAY_FILE" ]; then
                YESTERDAY_CUMULATIVE_TOTAL=$(jq '.cumulative.total_clones // 0' "$YESTERDAY_FILE")
                YESTERDAY_CUMULATIVE_UNIQUE=$(jq '.cumulative.unique_clones // 0' "$YESTERDAY_FILE")
                NEW_REPO_CUMULATIVE_TOTAL=$((YESTERDAY_CUMULATIVE_TOTAL + DAILY_DELTA_TOTAL))
                NEW_REPO_CUMULATIVE_UNIQUE=$((YESTERDAY_CUMULATIVE_UNIQUE + DAILY_DELTA_UNIQUE))
                echo "  > Yesterday Cumulative: $YESTERDAY_CUMULATIVE_TOTAL"
            else
                # First run since checkpoint - just add today's delta to checkpoint cumulative
                NEW_REPO_CUMULATIVE_TOTAL=$((REPO_CHECKPOINT_CUMULATIVE_TOTAL + DAILY_DELTA_TOTAL))
                NEW_REPO_CUMULATIVE_UNIQUE=$((REPO_CHECKPOINT_CUMULATIVE_UNIQUE + DAILY_DELTA_UNIQUE))
            fi
            
            # Add to Global Daily Counter
            GLOBAL_DAILY_DELTA_TOTAL=$((GLOBAL_DAILY_DELTA_TOTAL + DAILY_DELTA_TOTAL))
            GLOBAL_DAILY_DELTA_UNIQUE=$((GLOBAL_DAILY_DELTA_UNIQUE + DAILY_DELTA_UNIQUE))

            # Save Repo JSON
            jq -n \
              --arg repo "$REPO_FULL_NAME" \
              --arg ts "$READABLE_TIMESTAMP" \
              --arg start "$TRACKING_STARTED" \
              --arg checkpoint "$CHECKPOINT_TIMESTAMP" \
              --argjson c_total "$CURRENT_API_TOTAL" \
              --argjson c_unique "$CURRENT_API_UNIQUE" \
              --argjson yesterday_api_total "$YESTERDAY_API_TOTAL" \
              --argjson yesterday_api_unique "$YESTERDAY_API_UNIQUE" \
              --argjson daily_delta_total "$DAILY_DELTA_TOTAL" \
              --argjson daily_delta_unique "$DAILY_DELTA_UNIQUE" \
              --argjson checkpoint_cum_total "$REPO_CHECKPOINT_CUMULATIVE_TOTAL" \
              --argjson checkpoint_cum_unique "$REPO_CHECKPOINT_CUMULATIVE_UNIQUE" \
              --argjson cum_total "$NEW_REPO_CUMULATIVE_TOTAL" \
              --argjson cum_unique "$NEW_REPO_CUMULATIVE_UNIQUE" \
              '{repository: $repo, timestamp: $ts, tracking_started: $start, checkpoint_date: $checkpoint, current_period: {total_clones: $c_total, unique_clones: $c_unique}, yesterday_api_period: {total_clones: $yesterday_api_total, unique_clones: $yesterday_api_unique}, daily_delta: {total_clones: $daily_delta_total, unique_clones: $daily_delta_unique}, checkpoint_cumulative: {total_clones: $checkpoint_cum_total, unique_clones: $checkpoint_cum_unique}, cumulative: {total_clones: $cum_total, unique_clones: $cum_unique}}' > "analytics/$REPO_NAME/clones_$TIMESTAMP.json"
              
            echo "  > Saved. New Cumulative: $NEW_REPO_CUMULATIVE_TOTAL"
            echo ""
            
          done < extracted_repos.txt
          
          # --- ECOSYSTEM TOTALS ---
          # Always use checkpoint aggregate as base
          CHECKPOINT_AGGREGATE_FILE="analytics/aggregate_${CHECKPOINT_FILE_PATTERN}.json"
          
          if [ -f "$CHECKPOINT_AGGREGATE_FILE" ]; then
              echo "Using checkpoint aggregate file: $CHECKPOINT_AGGREGATE_FILE"
          else
              echo "Checkpoint aggregate file not found, using hardcoded values"
          fi
          
          # Find the most recent aggregate file (excluding today and checkpoint)
          RECENT_AGGREGATE_FILE=$(ls -t analytics/aggregate_*.json 2>/dev/null | grep -v "$TIMESTAMP" | grep -v "$CHECKPOINT_FILE_PATTERN" | head -1)
          
          # Start from checkpoint total
          PREV_ECOSYSTEM_TOTAL=$CHECKPOINT_TOTAL
          PREV_ECOSYSTEM_UNIQUE=$CHECKPOINT_UNIQUE
          
          # If we have a recent aggregate file, use its total
          if [ -f "$RECENT_AGGREGATE_FILE" ]; then
              PREV_ECOSYSTEM_TOTAL=$(jq '.ecosystem_totals.total_clones // 0' "$RECENT_AGGREGATE_FILE")
              PREV_ECOSYSTEM_UNIQUE=$(jq '.ecosystem_totals.unique_clones // 0' "$RECENT_AGGREGATE_FILE")
              echo "Found recent aggregate: $RECENT_AGGREGATE_FILE"
              echo "Previous ecosystem total: $PREV_ECOSYSTEM_TOTAL"
          else
              echo "No recent aggregate found, using checkpoint: $CHECKPOINT_TOTAL"
          fi
          
          # Add today's daily delta to get new total
          FINAL_ECOSYSTEM_TOTAL=$((PREV_ECOSYSTEM_TOTAL + GLOBAL_DAILY_DELTA_TOTAL))
          FINAL_ECOSYSTEM_UNIQUE=$((PREV_ECOSYSTEM_UNIQUE + GLOBAL_DAILY_DELTA_UNIQUE))
          
          # Save Ecosystem JSON
          jq -n \
            --arg ts "$READABLE_TIMESTAMP" \
            --arg checkpoint "$CHECKPOINT_TIMESTAMP" \
            --argjson checkpoint_total "$CHECKPOINT_TOTAL" \
            --argjson checkpoint_unique "$CHECKPOINT_UNIQUE" \
            --argjson daily_delta_total "$GLOBAL_DAILY_DELTA_TOTAL" \
            --argjson daily_delta_unique "$GLOBAL_DAILY_DELTA_UNIQUE" \
            --argjson total "$FINAL_ECOSYSTEM_TOTAL" \
            --argjson unique "$FINAL_ECOSYSTEM_UNIQUE" \
            '{timestamp: $ts, checkpoint_date: $checkpoint, checkpoint_totals: {total_clones: $checkpoint_total, unique_clones: $checkpoint_unique}, daily_delta: {total_clones: $daily_delta_total, unique_clones: $daily_delta_unique}, ecosystem_totals: {total_clones: $total, unique_clones: $unique}}' > "analytics/aggregate_$TIMESTAMP.json"
          
          echo "====================================="
          echo "DAILY SUMMARY"
          echo "Checkpoint Baseline: $CHECKPOINT_TOTAL (Dec 6)"
          echo "Previous Ecosystem Total: $PREV_ECOSYSTEM_TOTAL"
          echo "New Clones Today: +$GLOBAL_DAILY_DELTA_TOTAL"
          echo "New Ecosystem Total: $FINAL_ECOSYSTEM_TOTAL"
          echo "====================================="
          echo ""
          echo "CALCULATION LOGIC:"
          echo "1. Base: Always starts from checkpoint (Dec 6) values"
          echo "2. Daily Delta: API[today] - API[yesterday]"
          echo "3. Cumulative: Checkpoint cumulative + sum of daily deltas"
          echo "4. Ecosystem: Checkpoint total + sum of all daily deltas"
          echo "====================================="

      - name: Commit and push data
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add analytics/
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            COMMIT_TIME=$(TZ='Etc/GMT+3' date '+%Y-%m-%d %H:%M:%S GMT-3')
            git commit -m "Update clone statistics - $COMMIT_TIME"
            git push
          fi
