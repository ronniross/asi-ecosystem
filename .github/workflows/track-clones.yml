name: Track All Repository Clones

on:
  schedule:
    - cron: '33 3 * * *'
  workflow_dispatch:
  push:
    paths:
      - '.github/workflows/track-clones.yml'
      - 'README.md'

jobs:
  track-clones:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Initialize tracking system
        run: |
          mkdir -p analytics
          CURRENT_TIMESTAMP=$(TZ='Etc/GMT+3' date '+%Y-%m-%d %H:%M:%S GMT-3')
          
          if [ ! -f analytics/tracking-started.txt ]; then
            echo "First run detected - initializing tracking system"
            echo "$CURRENT_TIMESTAMP" > analytics/tracking-started.txt
            echo "Tracking started: $CURRENT_TIMESTAMP"
            echo "---"
          else
            TRACKING_STARTED=$(cat analytics/tracking-started.txt)
            echo "Tracking system started on: $TRACKING_STARTED"
            echo "Current run: $CURRENT_TIMESTAMP"
            echo "---"
          fi

      - name: Extract repositories from README
        run: |
          grep -oP 'https://github\.com/\K[\w-]+/[\w.-]+' README.md | sort -u > extracted_repos.txt
          echo "Extracted repositories:"
          cat extracted_repos.txt
          echo "---"

      - name: Fetch and record clone data
        env:
          TRAFFIC_TOKEN: ${{ secrets.TRAFFIC_TOKEN }}
        run: |
          TIMESTAMP=$(TZ='Etc/GMT+3' date +%Y-%m-%d_%H-%M-%S)
          READABLE_TIMESTAMP=$(TZ='Etc/GMT+3' date '+%Y-%m-%d %H:%M:%S GMT-3')
          
          # CHECKPOINT DATE - This is when we took the Dec 6 snapshot
          CHECKPOINT_TIMESTAMP="2025-12-06 00:55:13 GMT-3"
          CHECKPOINT_DATE="2025-12-06"
          
          echo "Processing repositories..."
          echo "Checkpoint date: $CHECKPOINT_DATE"
          echo ""
          
          # Track today's new clones
          GLOBAL_DAILY_DELTA_TOTAL=0
          GLOBAL_DAILY_DELTA_UNIQUE=0
          
          while IFS= read -r REPO_FULL_NAME || [ -n "$REPO_FULL_NAME" ]; do
            [[ -z "$REPO_FULL_NAME" ]] && continue
            REPO_FULL_NAME=$(echo "$REPO_FULL_NAME" | sed 's/[./]*$//')
            REPO_NAME="${REPO_FULL_NAME#*/}"
            
            echo "Fetching data for: $REPO_FULL_NAME"
            mkdir -p "analytics/$REPO_NAME"
            
            # --- API REQUEST ---
            HTTP_RESPONSE=$(curl -s -w "%{http_code}" -H "Authorization: token $TRAFFIC_TOKEN" "https://api.github.com/repos/$REPO_FULL_NAME/traffic/clones")
            HTTP_BODY=${HTTP_RESPONSE:0:${#HTTP_RESPONSE}-3}
            HTTP_STATUS=${HTTP_RESPONSE:${#HTTP_RESPONSE}-3}
            
            if [ "$HTTP_STATUS" != "200" ]; then
                echo "::error::Failed to fetch $REPO_FULL_NAME. Status: $HTTP_STATUS"
                continue
            fi

            # Current API Window (Last 14 Days)
            CURRENT_API_TOTAL=$(echo "$HTTP_BODY" | jq '.count // 0')
            CURRENT_API_UNIQUE=$(echo "$HTTP_BODY" | jq '.uniques // 0')
            
            echo "  > Current API: $CURRENT_API_TOTAL total / $CURRENT_API_UNIQUE unique"
            
            # --- FIND PREVIOUS FILE ---
            # Look for files NOT from today AND not from checkpoint date
            PREVIOUS_FILE=$(ls -t analytics/$REPO_NAME/clones_*.json 2>/dev/null | grep -v "$TIMESTAMP" | grep -v "$CHECKPOINT_DATE" | head -1)
            
            # Also check specifically for checkpoint file
            CHECKPOINT_FILE=$(ls analytics/$REPO_NAME/clones_${CHECKPOINT_DATE}_*.json 2>/dev/null | head -1)
            
            PREVIOUS_API_TOTAL=0
            PREVIOUS_API_UNIQUE=0
            PREVIOUS_CUMULATIVE_TOTAL=0
            PREVIOUS_CUMULATIVE_UNIQUE=0
            TRACKING_STARTED=$(cat analytics/tracking-started.txt)

            # Determine which file to use
            if [ -f "$PREVIOUS_FILE" ]; then
                # Use the most recent non-checkpoint file
                PREVIOUS_API_TOTAL=$(jq '.current_period.total_clones // 0' "$PREVIOUS_FILE")
                PREVIOUS_API_UNIQUE=$(jq '.current_period.unique_clones // 0' "$PREVIOUS_FILE")
                PREVIOUS_CUMULATIVE_TOTAL=$(jq '.cumulative.total_clones // 0' "$PREVIOUS_FILE")
                PREVIOUS_CUMULATIVE_UNIQUE=$(jq '.cumulative.unique_clones // 0' "$PREVIOUS_FILE")
                echo "  > Using previous file: $(basename $PREVIOUS_FILE)"
            elif [ -f "$CHECKPOINT_FILE" ]; then
                # Only checkpoint file exists - use it as baseline
                PREVIOUS_API_TOTAL=$(jq '.current_period.total_clones // 0' "$CHECKPOINT_FILE")
                PREVIOUS_API_UNIQUE=$(jq '.current_period.unique_clones // 0' "$CHECKPOINT_FILE")
                PREVIOUS_CUMULATIVE_TOTAL=$(jq '.cumulative.total_clones // 0' "$CHECKPOINT_FILE")
                PREVIOUS_CUMULATIVE_UNIQUE=$(jq '.cumulative.unique_clones // 0' "$CHECKPOINT_FILE")
                echo "  > Using checkpoint file as baseline"
            else
                echo "  > No previous data - this is first tracking for this repo"
            fi

            # --- CALCULATE DELTA ---
            if [ "$CURRENT_API_TOTAL" -ge "$PREVIOUS_API_TOTAL" ]; then
                DELTA_TOTAL=$((CURRENT_API_TOTAL - PREVIOUS_API_TOTAL))
            else
                # Window rollover
                DELTA_TOTAL=$CURRENT_API_TOTAL
            fi

            if [ "$CURRENT_API_UNIQUE" -ge "$PREVIOUS_API_UNIQUE" ]; then
                DELTA_UNIQUE=$((CURRENT_API_UNIQUE - PREVIOUS_API_UNIQUE))
            else
                DELTA_UNIQUE=$CURRENT_API_UNIQUE
            fi
            
            echo "  > Delta: $DELTA_TOTAL total / $DELTA_UNIQUE unique"

            # --- UPDATE CUMULATIVE ---
            NEW_CUMULATIVE_TOTAL=$((PREVIOUS_CUMULATIVE_TOTAL + DELTA_TOTAL))
            NEW_CUMULATIVE_UNIQUE=$((PREVIOUS_CUMULATIVE_UNIQUE + DELTA_UNIQUE))
            
            # Add to global counter
            GLOBAL_DAILY_DELTA_TOTAL=$((GLOBAL_DAILY_DELTA_TOTAL + DELTA_TOTAL))
            GLOBAL_DAILY_DELTA_UNIQUE=$((GLOBAL_DAILY_DELTA_UNIQUE + DELTA_UNIQUE))

            # Save repo JSON
            jq -n \
              --arg repo "$REPO_FULL_NAME" \
              --arg ts "$READABLE_TIMESTAMP" \
              --arg start "$TRACKING_STARTED" \
              --arg checkpoint "$CHECKPOINT_TIMESTAMP" \
              --argjson c_total "$CURRENT_API_TOTAL" \
              --argjson c_unique "$CURRENT_API_UNIQUE" \
              --argjson delta_total "$DELTA_TOTAL" \
              --argjson delta_unique "$DELTA_UNIQUE" \
              --argjson cum_total "$NEW_CUMULATIVE_TOTAL" \
              --argjson cum_unique "$NEW_CUMULATIVE_UNIQUE" \
              '{
                repository: $repo,
                timestamp: $ts,
                tracking_started: $start,
                checkpoint_date: $checkpoint,
                current_period: {
                  total_clones: $c_total,
                  unique_clones: $c_unique
                },
                daily_delta: {
                  total_clones: $delta_total,
                  unique_clones: $delta_unique
                },
                cumulative: {
                  total_clones: $cum_total,
                  unique_clones: $cum_unique
                }
              }' > "analytics/$REPO_NAME/clones_$TIMESTAMP.json"
              
            echo "  > Cumulative: $NEW_CUMULATIVE_TOTAL total / $NEW_CUMULATIVE_UNIQUE unique"
            echo ""
            
          done < extracted_repos.txt
          
          # --- ECOSYSTEM TOTALS (THE SIMPLE PART) ---
          
          # Get the Dec 6 aggregate file to use as starting point
          CHECKPOINT_AGGREGATE="analytics/aggregate_${CHECKPOINT_DATE}_00-55-13.json"
          
          # Find most recent aggregate (excluding today's runs)
          LAST_AGGREGATE=$(ls -t analytics/aggregate_*.json 2>/dev/null | grep -v "$TIMESTAMP" | head -1)
          
          if [ -f "$LAST_AGGREGATE" ]; then
             # Use last aggregate's ecosystem total
             PREV_TOTAL=$(jq '.ecosystem_totals.total_clones // 0' "$LAST_AGGREGATE")
             PREV_UNIQUE=$(jq '.ecosystem_totals.unique_clones // 0' "$LAST_AGGREGATE")
             echo "Using previous aggregate: $PREV_TOTAL / $PREV_UNIQUE"
          elif [ -f "$CHECKPOINT_AGGREGATE" ]; then
             # Use checkpoint as baseline
             PREV_TOTAL=$(jq '.ecosystem_totals.total_clones // 0' "$CHECKPOINT_AGGREGATE")
             PREV_UNIQUE=$(jq '.ecosystem_totals.unique_clones // 0' "$CHECKPOINT_AGGREGATE")
             echo "Using checkpoint as baseline: $PREV_TOTAL / $PREV_UNIQUE"
          else
             # Fallback to hardcoded checkpoint
             PREV_TOTAL=1254
             PREV_UNIQUE=966
             echo "Using hardcoded checkpoint: $PREV_TOTAL / $PREV_UNIQUE"
          fi
          
          # SIMPLE ADDITION
          FINAL_TOTAL=$((PREV_TOTAL + GLOBAL_DAILY_DELTA_TOTAL))
          FINAL_UNIQUE=$((PREV_UNIQUE + GLOBAL_DAILY_DELTA_UNIQUE))
          
          # Save aggregate
          jq -n \
            --arg ts "$READABLE_TIMESTAMP" \
            --arg checkpoint "$CHECKPOINT_TIMESTAMP" \
            --argjson checkpoint_total "1254" \
            --argjson checkpoint_unique "966" \
            --argjson daily_delta_total "$GLOBAL_DAILY_DELTA_TOTAL" \
            --argjson daily_delta_unique "$GLOBAL_DAILY_DELTA_UNIQUE" \
            --argjson total "$FINAL_TOTAL" \
            --argjson unique "$FINAL_UNIQUE" \
            '{
              timestamp: $ts,
              checkpoint: {
                date: $checkpoint,
                total_clones: $checkpoint_total,
                unique_clones: $checkpoint_unique
              },
              daily_delta: {
                total_clones: $daily_delta_total,
                unique_clones: $daily_delta_unique
              },
              ecosystem_totals: {
                total_clones: $total,
                unique_clones: $unique
              }
            }' > "analytics/aggregate_$TIMESTAMP.json"
          
          echo "====================================="
          echo "ECOSYSTEM CALCULATION:"
          echo "$PREV_TOTAL + $GLOBAL_DAILY_DELTA_TOTAL = $FINAL_TOTAL"
          echo "$PREV_UNIQUE + $GLOBAL_DAILY_DELTA_UNIQUE = $FINAL_UNIQUE"
          echo "====================================="

      - name: Commit and push data
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add analytics/
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            COMMIT_TIME=$(TZ='Etc/GMT+3' date '+%Y-%m-%d %H:%M:%S GMT-3')
            git commit -m "Update clone statistics - $COMMIT_TIME"
            git push
          fi
